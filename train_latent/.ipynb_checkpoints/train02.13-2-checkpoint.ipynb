{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba202ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 13 16:28:48 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 36%   65C    P2             198W / 200W |  23483MiB / 24564MiB |     91%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "| 33%   61C    P0              92W / 200W |     28MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    0   N/A  N/A      3196      C   ...cpark/anaconda3/envs/ste/bin/python    23466MiB |\r\n",
      "|    1   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1343      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d51ab",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac98774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_size = 256\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 8\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 512\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x21,64m32,64x13,128m64,128x7,256m128\"\n",
    "hp.enc_blocks = \"256x3,256d2,128x8,128d2,64x12,64d2,32x17,32d2,16x7,16d2,8x5,8d2,4x5,4d4,1x4\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 1e-4\n",
    "\n",
    "# Diffusion\n",
    "hp.scheduler = DDPMScheduler()\n",
    "hp.diff_middle_width = 128\n",
    "hp.diff_residual = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777903",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b84157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae_latent import Model as VAE\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_decoder import Decoder\n",
    "from model.loss.dmol import Loss\n",
    "\n",
    "from model.main.latent_diffusion import Model\n",
    "from model.latent_diffusion.denorm_latent_diffusion import LatentDiffusion\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c033d586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_diffusion 75.9298095703125\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "vae = VAE(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "model = Model(LatentDiffusion(hp)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 1 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d4c2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3ac36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/lse/train_latent/train02.13-2/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, optimizer = load(save_dir, 60000, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e406eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data/checkpoint/ffhq256-iter-1700000-model-ema.th'\n",
    "# Checkpoint 파일 로드\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model_state_dict = vae.state_dict()\n",
    "for key in checkpoint.keys():\n",
    "    if key.startswith('encoder'):\n",
    "        model_key = 'encoder.' + key\n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "    if key.startswith('decoder'):\n",
    "        if key.startswith('decoder.out_net'):\n",
    "            model_key = 'loss.' + key[8:]\n",
    "        else:\n",
    "            model_key = 'decoder.' + key\n",
    "            \n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "            \n",
    "vae.load_state_dict(model_state_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282214",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING TEST\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f764a1abbc0>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.vdvae_data import set_up_data\n",
    "\n",
    "hp, data_train, data_valid_or_test, preprocess_fn = set_up_data(hp)\n",
    "train_loader = DataLoader(data_train, batch_size=hp.n_batch, drop_last=True, pin_memory=True)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98a82",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8269c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(data_input, vae):\n",
    "    vae.eval()\n",
    "    data = {'x': data_input}\n",
    "    with torch.no_grad():\n",
    "        stats = vae.get_latent(data, get_latents=True)\n",
    "    return stats['stats']\n",
    "\n",
    "def train_step(stats, model, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    data = {'stats': stats}\n",
    "    data = model(data)\n",
    "    loss = 0\n",
    "    for key in data:\n",
    "        if 'loss' in key:\n",
    "            loss = loss + data[key]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loss 0.02222507819533348\n",
      "20 loss 0.029323510825634003\n",
      "30 loss 0.021353332325816154\n",
      "40 loss 0.022270776331424713\n",
      "50 loss 0.022930605337023735\n",
      "60 loss 0.022053692489862442\n",
      "70 loss 0.024282380938529968\n",
      "80 loss 0.022990113124251366\n",
      "90 loss 0.024588994681835175\n",
      "100 loss 0.022294051945209503\n",
      "110 loss 0.02225852943956852\n",
      "120 loss 0.021886266767978668\n",
      "130 loss 0.020126555114984512\n",
      "140 loss 0.021204177290201187\n",
      "150 loss 0.022085674107074738\n",
      "160 loss 0.02162209153175354\n",
      "170 loss 0.022418295964598656\n",
      "180 loss 0.020222390070557594\n",
      "190 loss 0.026434635743498802\n",
      "200 loss 0.026373514905571938\n",
      "210 loss 0.021885719150304794\n",
      "220 loss 0.02105303294956684\n",
      "230 loss 0.024909496307373047\n",
      "240 loss 0.02038915641605854\n",
      "250 loss 0.020309392362833023\n",
      "260 loss 0.023748693987727165\n",
      "270 loss 0.02173074707388878\n",
      "280 loss 0.024321287870407104\n",
      "290 loss 0.023271648213267326\n",
      "300 loss 0.01871112361550331\n",
      "310 loss 0.018938884139060974\n",
      "320 loss 0.022631490603089333\n",
      "330 loss 0.023009970784187317\n",
      "340 loss 0.018327483907341957\n",
      "350 loss 0.022732922807335854\n",
      "360 loss 0.022165143862366676\n",
      "370 loss 0.022724276408553123\n",
      "380 loss 0.018118727952241898\n",
      "390 loss 0.025838419795036316\n",
      "400 loss 0.020858675241470337\n",
      "410 loss 0.023823270574212074\n",
      "420 loss 0.022303923964500427\n",
      "430 loss 0.022939205169677734\n",
      "440 loss 0.019049208611249924\n",
      "450 loss 0.0211492870002985\n",
      "460 loss 0.020183436572551727\n",
      "470 loss 0.024218140169978142\n",
      "480 loss 0.02186867967247963\n",
      "490 loss 0.02150312438607216\n",
      "500 loss 0.023447511717677116\n",
      "510 loss 0.02193624898791313\n",
      "520 loss 0.01948065496981144\n",
      "530 loss 0.01903550699353218\n",
      "540 loss 0.02034645341336727\n",
      "550 loss 0.01936679147183895\n",
      "560 loss 0.022900309413671494\n",
      "570 loss 0.01887834630906582\n",
      "580 loss 0.021175792440772057\n",
      "590 loss 0.0200029369443655\n",
      "600 loss 0.01779354363679886\n",
      "610 loss 0.023386580869555473\n",
      "620 loss 0.022624792531132698\n",
      "630 loss 0.020975187420845032\n",
      "640 loss 0.019312728196382523\n",
      "650 loss 0.02146059088408947\n",
      "660 loss 0.019821790978312492\n",
      "670 loss 0.020624279975891113\n",
      "680 loss 0.02100677229464054\n",
      "690 loss 0.021026311442255974\n",
      "700 loss 0.019155442714691162\n",
      "710 loss 0.02479693479835987\n",
      "720 loss 0.019282450899481773\n",
      "730 loss 0.02047983556985855\n",
      "740 loss 0.018721820786595345\n",
      "750 loss 0.023725444450974464\n",
      "760 loss 0.024993931874632835\n",
      "770 loss 0.022770805284380913\n",
      "780 loss 0.022385496646165848\n",
      "790 loss 0.023254116997122765\n",
      "800 loss 0.01848454959690571\n",
      "810 loss 0.021219586953520775\n",
      "820 loss 0.02206137590110302\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "resize = transforms.Resize((hp.image_size, hp.image_size))\n",
    "\n",
    "while True:\n",
    "    for x in train_loader:\n",
    "        # Get Latents from pretrained-VAE\n",
    "        x[0] = resize(x[0].permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        data_input = data_input.to(device)\n",
    "        target = target.to(device)\n",
    "        stats = get_latent(data_input, vae)\n",
    "        loss = train_step(stats, model, optimizer)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, 'loss', loss.item())\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, optimizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3915c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320125bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
