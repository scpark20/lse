{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba202ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 13 15:48:39 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 42%   62C    P0              92W / 450W |     11MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "| 50%   67C    P2              86W / 450W |  23501MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    1   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1343      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "|    1   N/A  N/A      3068      C   ...cpark/anaconda3/envs/ste/bin/python    23466MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d51ab",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac98774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_size = 256\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 8\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 512\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x21,64m32,64x13,128m64,128x7,256m128\"\n",
    "hp.enc_blocks = \"256x3,256d2,128x8,128d2,64x12,64d2,32x17,32d2,16x7,16d2,8x5,8d2,4x5,4d4,1x4\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 1e-4\n",
    "\n",
    "# Diffusion\n",
    "hp.scheduler = DDPMScheduler()\n",
    "hp.diff_middle_width = 128\n",
    "hp.diff_residual = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777903",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b84157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae_latent import Model as VAE\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_decoder import Decoder\n",
    "from model.loss.dmol import Loss\n",
    "\n",
    "from model.main.latent_diffusion import Model\n",
    "from model.latent_diffusion.default_latent_diffusion import LatentDiffusion\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c033d586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_diffusion 75.9298095703125\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "vae = VAE(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "model = Model(LatentDiffusion(hp)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 1 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d4c2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3ac36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/lse/train_latent/train02.13-1/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, optimizer = load(save_dir, 60000, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e406eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data/checkpoint/ffhq256-iter-1700000-model-ema.th'\n",
    "# Checkpoint 파일 로드\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model_state_dict = vae.state_dict()\n",
    "for key in checkpoint.keys():\n",
    "    if key.startswith('encoder'):\n",
    "        model_key = 'encoder.' + key\n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "    if key.startswith('decoder'):\n",
    "        if key.startswith('decoder.out_net'):\n",
    "            model_key = 'loss.' + key[8:]\n",
    "        else:\n",
    "            model_key = 'decoder.' + key\n",
    "            \n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "            \n",
    "vae.load_state_dict(model_state_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282214",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING TEST\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8d7bb90830>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.vdvae_data import set_up_data\n",
    "\n",
    "hp, data_train, data_valid_or_test, preprocess_fn = set_up_data(hp)\n",
    "train_loader = DataLoader(data_train, batch_size=hp.n_batch, drop_last=True, pin_memory=True)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98a82",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8269c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(data_input, vae):\n",
    "    vae.eval()\n",
    "    data = {'x': data_input}\n",
    "    with torch.no_grad():\n",
    "        stats = vae.get_latent(data, get_latents=True)\n",
    "    return stats['stats']\n",
    "\n",
    "def train_step(stats, model, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    data = {'stats': stats}\n",
    "    data = model(data)\n",
    "    loss = 0\n",
    "    for key in data:\n",
    "        if 'loss' in key:\n",
    "            loss = loss + data[key]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loss 0.36587944626808167\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "resize = transforms.Resize((hp.image_size, hp.image_size))\n",
    "\n",
    "while True:\n",
    "    for x in train_loader:\n",
    "        # Get Latents from pretrained-VAE\n",
    "        x[0] = resize(x[0].permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        data_input = data_input.to(device)\n",
    "        target = target.to(device)\n",
    "        stats = get_latent(data_input, vae)\n",
    "        loss = train_step(stats, model, optimizer)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, 'loss', loss.item())\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, optimizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
