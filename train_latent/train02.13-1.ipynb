{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba202ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 13 15:48:39 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 42%   62C    P0              92W / 450W |     11MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "| 50%   67C    P2              86W / 450W |  23501MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    1   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1343      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "|    1   N/A  N/A      3068      C   ...cpark/anaconda3/envs/ste/bin/python    23466MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d51ab",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac98774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_size = 256\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 8\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 512\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x21,64m32,64x13,128m64,128x7,256m128\"\n",
    "hp.enc_blocks = \"256x3,256d2,128x8,128d2,64x12,64d2,32x17,32d2,16x7,16d2,8x5,8d2,4x5,4d4,1x4\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 1e-4\n",
    "\n",
    "# Diffusion\n",
    "hp.scheduler = DDPMScheduler()\n",
    "hp.diff_middle_width = 128\n",
    "hp.diff_residual = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777903",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b84157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae_latent import Model as VAE\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_decoder import Decoder\n",
    "from model.loss.dmol import Loss\n",
    "\n",
    "from model.main.latent_diffusion import Model\n",
    "from model.latent_diffusion.default_latent_diffusion import LatentDiffusion\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c033d586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_diffusion 75.9298095703125\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "vae = VAE(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "model = Model(LatentDiffusion(hp)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 1 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d4c2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3ac36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/lse/train_latent/train02.13-1/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, optimizer = load(save_dir, 60000, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e406eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data/checkpoint/ffhq256-iter-1700000-model-ema.th'\n",
    "# Checkpoint 파일 로드\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model_state_dict = vae.state_dict()\n",
    "for key in checkpoint.keys():\n",
    "    if key.startswith('encoder'):\n",
    "        model_key = 'encoder.' + key\n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "    if key.startswith('decoder'):\n",
    "        if key.startswith('decoder.out_net'):\n",
    "            model_key = 'loss.' + key[8:]\n",
    "        else:\n",
    "            model_key = 'decoder.' + key\n",
    "            \n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "            \n",
    "vae.load_state_dict(model_state_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282214",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING TEST\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8d7bb90830>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.vdvae_data import set_up_data\n",
    "\n",
    "hp, data_train, data_valid_or_test, preprocess_fn = set_up_data(hp)\n",
    "train_loader = DataLoader(data_train, batch_size=hp.n_batch, drop_last=True, pin_memory=True)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98a82",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8269c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(data_input, vae):\n",
    "    vae.eval()\n",
    "    data = {'x': data_input}\n",
    "    with torch.no_grad():\n",
    "        stats = vae.get_latent(data, get_latents=True)\n",
    "    return stats['stats']\n",
    "\n",
    "def train_step(stats, model, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    data = {'stats': stats}\n",
    "    data = model(data)\n",
    "    loss = 0\n",
    "    for key in data:\n",
    "        if 'loss' in key:\n",
    "            loss = loss + data[key]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 loss 0.3111901879310608\n",
      "1020 loss 0.30360347032546997\n",
      "1030 loss 0.2991155683994293\n",
      "1040 loss 0.32521283626556396\n",
      "1050 loss 0.31779173016548157\n",
      "1060 loss 0.30991458892822266\n",
      "1070 loss 0.30875852704048157\n",
      "1080 loss 0.31427285075187683\n",
      "1090 loss 0.316972017288208\n",
      "1100 loss 0.33765801787376404\n",
      "1110 loss 0.3071352541446686\n",
      "1120 loss 0.34383049607276917\n",
      "1130 loss 0.31525224447250366\n",
      "1140 loss 0.32365652918815613\n",
      "1150 loss 0.3244491219520569\n",
      "1160 loss 0.2755028009414673\n",
      "1170 loss 0.29115402698516846\n",
      "1180 loss 0.34071803092956543\n",
      "1190 loss 0.32351312041282654\n",
      "1200 loss 0.30458804965019226\n",
      "1210 loss 0.3096097409725189\n",
      "1220 loss 0.3267917037010193\n",
      "1230 loss 0.3597162961959839\n",
      "1240 loss 0.32251691818237305\n",
      "1250 loss 0.3040403425693512\n",
      "1260 loss 0.3288004398345947\n",
      "1270 loss 0.2929248809814453\n",
      "1280 loss 0.3433154821395874\n",
      "1290 loss 0.27827122807502747\n",
      "1300 loss 0.27865222096443176\n",
      "1310 loss 0.29950299859046936\n",
      "1320 loss 0.32086238265037537\n",
      "1330 loss 0.3518436551094055\n",
      "1340 loss 0.3256470561027527\n",
      "1350 loss 0.3080311715602875\n",
      "1360 loss 0.3139769434928894\n",
      "1370 loss 0.29227837920188904\n",
      "1380 loss 0.28068703413009644\n",
      "1390 loss 0.33304738998413086\n",
      "1400 loss 0.3128190338611603\n",
      "1410 loss 0.31492987275123596\n",
      "1420 loss 0.33086860179901123\n",
      "1430 loss 0.3302655816078186\n",
      "1440 loss 0.3089659512042999\n",
      "1450 loss 0.300294429063797\n",
      "1460 loss 0.2976208031177521\n",
      "1470 loss 0.29993635416030884\n",
      "1480 loss 0.30465400218963623\n",
      "1490 loss 0.3636109232902527\n",
      "1500 loss 0.33957552909851074\n",
      "1510 loss 0.34026822447776794\n",
      "1520 loss 0.2970369756221771\n",
      "1530 loss 0.3029560446739197\n",
      "1540 loss 0.3053063452243805\n",
      "1550 loss 0.3102627098560333\n",
      "1560 loss 0.3123919367790222\n",
      "1570 loss 0.33565425872802734\n",
      "1580 loss 0.34840914607048035\n",
      "1590 loss 0.3422923684120178\n",
      "1600 loss 0.28917843103408813\n",
      "1610 loss 0.2945355772972107\n",
      "1620 loss 0.30635368824005127\n",
      "1630 loss 0.3221673369407654\n",
      "1640 loss 0.30654987692832947\n",
      "1650 loss 0.29926764965057373\n",
      "1660 loss 0.32599690556526184\n",
      "1670 loss 0.30289825797080994\n",
      "1680 loss 0.3280608654022217\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "resize = transforms.Resize((hp.image_size, hp.image_size))\n",
    "\n",
    "while True:\n",
    "    for x in train_loader:\n",
    "        # Get Latents from pretrained-VAE\n",
    "        x[0] = resize(x[0].permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        data_input = data_input.to(device)\n",
    "        target = target.to(device)\n",
    "        stats = get_latent(data_input, vae)\n",
    "        loss = train_step(stats, model, optimizer)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, 'loss', loss.item())\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, optimizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
