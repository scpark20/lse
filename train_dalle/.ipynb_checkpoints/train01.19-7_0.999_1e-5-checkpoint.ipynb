{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b380d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0ed27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 10:24:48 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   259W / 300W |  27899MiB / 80994MiB |      8%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   242W / 300W |  35963MiB / 80994MiB |     11%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    44W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   277W / 300W |  27899MiB / 80994MiB |      9%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    41W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    44W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A   1440611      C   ...a3/envs/scpark/bin/python    27861MiB |\n",
      "|    1   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A   1440625      C   ...a3/envs/scpark/bin/python    35925MiB |\n",
      "|    2   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A   1495473      C   ...a3/envs/scpark/bin/python    27861MiB |\n",
      "|    5   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282baf85",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bc0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_quantizer_dec import Model\n",
    "from model.encoder.net_64_encoder import Encoder\n",
    "from model.prior.dalle_randn_prior import Prior\n",
    "from model.latent.dalle_lse_latent import Latent\n",
    "from model.quantizer.dalle_nearest_quantizer import Quantizer\n",
    "from model.decoder.net_64_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f2799",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0bd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.img_size = 64\n",
    "hp.n_resblocks = 6\n",
    "hp.z_dim = 64\n",
    "hp.n_prior_embeddings = 512\n",
    "hp.init_log_sigma = -3\n",
    "hp.const_sigma = True\n",
    "hp.quantize = False\n",
    "hp.prior_mu = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935abe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 1.2191162109375\n",
      "encoder.encoder 1.2191162109375\n",
      "prior 0.126953125\n",
      "latent 3.814697265625e-06\n",
      "quantizer 0.0\n",
      "decoder 1.0611686706542969\n",
      "decoder.decoder 1.0611686706542969\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(1):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Quantizer(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4d60f",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27598aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 77172\r\n",
      "-rw-rw-r-- 1 scpark scpark       40  1월 22 10:24 events.out.tfevents.1705886631.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark     7043  1월 22 10:24 events.out.tfevents.1705886638.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark       40  1월 22 10:23 events.out.tfevents.1705886603.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark       40  1월 22 10:23 events.out.tfevents.1705886610.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark 11691847  1월 22 10:23 events.out.tfevents.1705863404.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 10:23 save_78801\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 09:40 save_70000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 08:51 save_60000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 08:02 save_50000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 07:13 save_40000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 06:23 save_30000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 05:34 save_20000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7477768  1월 22 04:45 save_10000\r\n",
      "-rw-rw-r-- 1 scpark scpark  7470716  1월 22 03:57 save_0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train_dalle/train01.19-7_0.999_1e-5/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if True:\n",
    "    step, model_list, optimizer_list = load_model_list(save_dir, 78801, model_list, optimizer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a993d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f6cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA\n",
    "\n",
    "class MyCelebA(CelebA):\n",
    "    \"\"\"\n",
    "    A work-around to address issues with pytorch's celebA dataset class.\n",
    "    \n",
    "    Download and Extract\n",
    "    URL : https://drive.google.com/file/d/1m8-EBPgi5MRubrm6iQjafK2QMHDBMSfJ/view?usp=sharing\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_integrity(self) -> bool:\n",
    "        return True\n",
    "\n",
    "root = '/data'\n",
    "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.CenterCrop(148),\n",
    "                                       transforms.Resize(hp.img_size),\n",
    "                                       transforms.ToTensor(),])\n",
    "train_dataset = MyCelebA(root, split='train', transform=train_transforms, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b4796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034ab95",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f4ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(8):\n",
    "        plt.subplot(1, 8, i+1)\n",
    "        plt.imshow(_x[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a46898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(start_value, end_value, current_index, start_index, end_index):\n",
    "    if current_index > end_index:\n",
    "        return end_value\n",
    "    if current_index < start_index:\n",
    "        return start_value\n",
    "\n",
    "    grad = (end_value - start_value) / (end_index - start_index)\n",
    "    y = start_value + grad * (current_index - start_index)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5cfbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81128\n",
      "lse_loss -205.79254150390625\n",
      "commit_loss 0.011034611612558365\n",
      "recon_loss 0.0002720238408073783\n",
      "81129\n",
      "lse_loss -205.84494018554688\n",
      "commit_loss 0.011246749199926853\n",
      "recon_loss 0.0002723298384808004\n",
      "81130\n",
      "lse_loss -205.66055297851562\n",
      "commit_loss 0.010828458704054356\n",
      "recon_loss 0.00026280127349309623\n",
      "81131\n",
      "lse_loss -204.67974853515625\n",
      "commit_loss 0.010379767045378685\n",
      "recon_loss 0.0002646344364620745\n",
      "81132\n",
      "lse_loss -205.38351440429688\n",
      "commit_loss 0.010602518916130066\n",
      "recon_loss 0.0002730163396336138\n",
      "81133\n",
      "lse_loss -204.18411254882812\n",
      "commit_loss 0.010134449228644371\n",
      "recon_loss 0.0002681459009181708\n",
      "81134\n",
      "lse_loss -204.90579223632812\n",
      "commit_loss 0.010308093391358852\n",
      "recon_loss 0.00026882876409217715\n",
      "81135\n",
      "lse_loss -198.6016845703125\n",
      "commit_loss 0.010332605801522732\n",
      "recon_loss 0.00029489619191735983\n",
      "81136\n",
      "lse_loss -204.56381225585938\n",
      "commit_loss 0.009607414714992046\n",
      "recon_loss 0.000272966775810346\n",
      "81137\n",
      "lse_loss -203.86782836914062\n",
      "commit_loss 0.009687922894954681\n",
      "recon_loss 0.0002641879837028682\n",
      "81138\n",
      "lse_loss -196.29647827148438\n",
      "commit_loss 0.009383966214954853\n",
      "recon_loss 0.00030608553788624704\n",
      "81139\n",
      "lse_loss -202.085693359375\n",
      "commit_loss 0.009279845282435417\n",
      "recon_loss 0.00026972408522851765\n",
      "81140\n",
      "lse_loss -203.60098266601562\n",
      "commit_loss 0.009207334369421005\n",
      "recon_loss 0.0002575084799900651\n",
      "81141\n",
      "lse_loss -194.06582641601562\n",
      "commit_loss 0.009318213909864426\n",
      "recon_loss 0.00027073873206973076\n",
      "81142\n",
      "lse_loss -203.15081787109375\n",
      "commit_loss 0.009376652538776398\n",
      "recon_loss 0.0002678625751286745\n",
      "81143\n",
      "lse_loss -202.78814697265625\n",
      "commit_loss 0.009669620543718338\n",
      "recon_loss 0.0002746697573456913\n",
      "81144\n",
      "lse_loss -203.77899169921875\n",
      "commit_loss 0.009432691149413586\n",
      "recon_loss 0.00026172478101216257\n",
      "81145\n",
      "lse_loss -203.64968872070312\n",
      "commit_loss 0.009895537048578262\n",
      "recon_loss 0.0003083500196225941\n",
      "81146\n",
      "lse_loss -202.47259521484375\n",
      "commit_loss 0.009336831048130989\n",
      "recon_loss 0.0002983821032103151\n",
      "81147\n",
      "lse_loss -202.4749755859375\n",
      "commit_loss 0.009338119067251682\n",
      "recon_loss 0.0002919125836342573\n",
      "81148\n",
      "lse_loss -202.4906005859375\n",
      "commit_loss 0.009276721626520157\n",
      "recon_loss 0.00027339899679645896\n",
      "81149\n",
      "lse_loss -202.67843627929688\n",
      "commit_loss 0.00923597440123558\n",
      "recon_loss 0.0002658774028532207\n",
      "81150\n",
      "lse_loss -201.698974609375\n",
      "commit_loss 0.008671971969306469\n",
      "recon_loss 0.0002884460845962167\n",
      "81151\n",
      "lse_loss -202.82644653320312\n",
      "commit_loss 0.008402482606470585\n",
      "recon_loss 0.00027670018607750535\n",
      "81152\n",
      "lse_loss -174.000732421875\n",
      "commit_loss 0.00837359856814146\n",
      "recon_loss 0.0003352037747390568\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, latent_temp=1)\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'lse_loss' in key:\n",
    "                    loss = loss + data[key] * 1e-5\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                elif 'commit_loss' in key:\n",
    "                    loss = loss + data[key] * 1e-1\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]        \n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, latent_temp=1, quantize=True)\n",
    "                \n",
    "            writer.add_scalar('eval_recon_loss', data['recon_loss'].item(), step)    \n",
    "\n",
    "            x = data['x']\n",
    "            y = data['y']\n",
    "            \n",
    "            plot(x)\n",
    "            plot(y)\n",
    "            \n",
    "            from sklearn.decomposition import PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            e = model.prior.prior.data.cpu().numpy()\n",
    "            pca.fit(e)\n",
    "            e_pca = pca.transform(e)\n",
    "            z_pca = pca.transform(data['z'].permute(0, 2, 3, 1).reshape(-1, hp.z_dim).data.cpu().numpy())\n",
    "            plt.figure(figsize=[10, 10])\n",
    "            plt.scatter(e_pca[:, 0], e_pca[:, 1], marker='x', alpha=1.0, color='black')\n",
    "            plt.scatter(z_pca[:, 0], z_pca[:, 1], marker='o', alpha=0.01, color='blue')\n",
    "            plt.grid()\n",
    "            plt.show() \n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7b254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86b2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
