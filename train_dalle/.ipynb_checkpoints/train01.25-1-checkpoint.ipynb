{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b380d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0ed27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 25 02:58:43 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    43W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   66C    P0   303W / 300W |  24081MiB / 80994MiB |     98%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   157W / 300W |  10347MiB / 80994MiB |     22%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    65W / 300W |  10347MiB / 80994MiB |     14%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    46W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    40W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   171W / 300W |   8299MiB / 80994MiB |     24%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A   1738762      C   ...a3/envs/scpark/bin/python    24043MiB |\n",
      "|    2   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A   1996033      C   ...a3/envs/scpark/bin/python    10309MiB |\n",
      "|    3   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A   2027363      C   ...a3/envs/scpark/bin/python    10309MiB |\n",
      "|    4   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    5   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A   1986311      C   ...a3/envs/scpark/bin/python     8261MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282baf85",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bc0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_quantizer_dec import Model\n",
    "from model.encoder.conv2d_encoder import Encoder\n",
    "from model.prior.rand_prior import Prior\n",
    "from model.latent.lse_latent import Latent\n",
    "from model.quantizer.nearest_quantizer import Quantizer\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f2799",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf0bd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 1\n",
    "hp.out_dim = 1\n",
    "hp.z_activation = F.tanh\n",
    "hp.z_dim = 2\n",
    "hp.n_prior_embeddings = 32\n",
    "hp.const_sigma = False\n",
    "hp.quantize = False\n",
    "hp.prior_mu = 0.0\n",
    "\n",
    "hp.M = hp.n_prior_embeddings\n",
    "hp.N = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15d80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ''' Find Optimum Log-Sigma'''\n",
    "from util.loglikelihood import get_optimum_log_sigma\n",
    "\n",
    "# p_samples1 = (torch.rand(hp.M, 2)*2-1).cuda()\n",
    "# p_samples2 = (torch.rand(hp.N, 2)*2-1).cuda()\n",
    "# log_sigmas = np.array([get_optimum_log_sigma(p_samples1, p_samples2, -10, 10) for _ in range(100)])\n",
    "#hp.init_log_sigma = np.median(log_sigmas)\n",
    "hp.init_log_sigma = 0\n",
    "print(hp.init_log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "935abe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 6.004646301269531\n",
      "encoder.convs 5.989013671875\n",
      "encoder.linear 0.01563262939453125\n",
      "prior 0.0003662109375\n",
      "latent 3.814697265625e-06\n",
      "quantizer 0.0\n",
      "decoder 6.044322967529297\n",
      "decoder.linear 0.0234375\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(1):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Quantizer(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4d60f",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27598aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 77184\r\n",
      "-rw-rw-r-- 1 scpark scpark   256058  1월 25 03:08 events.out.tfevents.1706119569.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark   871524  1월 25 03:06 events.out.tfevents.1706119128.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark 37976107  1월 25 03:06 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark   281024  1월 25 02:58 events.out.tfevents.1706118985.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark   158384  1월 25 02:56 events.out.tfevents.1706118864.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark   243940  1월 25 02:53 events.out.tfevents.1706118717.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark   354262  1월 25 02:51 events.out.tfevents.1706118548.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark   709157  1월 25 02:49 events.out.tfevents.1706118187.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark 37987461  1월 25 02:47 save_3774\r\n",
      "-rw-rw-r-- 1 scpark scpark   102812  1월 25 02:42 events.out.tfevents.1706118128.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark    52227  1월 25 02:41 events.out.tfevents.1706118037.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark      263  1월 25 02:40 events.out.tfevents.1706117969.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark      222  1월 25 02:39 events.out.tfevents.1706117874.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark       40  1월 25 02:37 events.out.tfevents.1706117765.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark       40  1월 25 02:37 events.out.tfevents.1706117801.GPUSVR11\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train_dalle/train01.25-1/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model_list, optimizer_list = load_model_list(save_dir, 20000, model_list, optimizer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a993d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f6cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations applied on each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the image to 32x32\n",
    "    transforms.ToTensor(),         # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5), (0.5)) \n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=hp.N, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=2048, shuffle=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2b4796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034ab95",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5f4ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(8):\n",
    "        plt.subplot(1, 8, i+1)\n",
    "        plt.imshow(_x[i, :, :, 0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a46898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(start_value, end_value, current_index, start_index, end_index):\n",
    "    if current_index > end_index:\n",
    "        return end_value\n",
    "    if current_index < start_index:\n",
    "        return start_value\n",
    "\n",
    "    grad = (end_value - start_value) / (end_index - start_index)\n",
    "    y = start_value + grad * (current_index - start_index)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b352d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5cfbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13063\n",
      "lse_loss -1.1842775344848633\n",
      "commit_loss 0.02034572884440422\n",
      "recon_loss 0.09771309792995453\n",
      "13064\n",
      "lse_loss -1.302511215209961\n",
      "commit_loss 0.018011420965194702\n",
      "recon_loss 0.10416203737258911\n",
      "13065\n",
      "lse_loss -1.3461995124816895\n",
      "commit_loss 0.013711324892938137\n",
      "recon_loss 0.1371973603963852\n",
      "13066\n",
      "lse_loss -1.407862663269043\n",
      "commit_loss 0.014484802260994911\n",
      "recon_loss 0.15103283524513245\n",
      "13067\n",
      "lse_loss -1.4655399322509766\n",
      "commit_loss 0.011373140849173069\n",
      "recon_loss 0.16009831428527832\n",
      "13068\n",
      "lse_loss -1.4723644256591797\n",
      "commit_loss 0.01187901757657528\n",
      "recon_loss 0.16063767671585083\n",
      "13069\n",
      "lse_loss -1.5271310806274414\n",
      "commit_loss 0.012396905571222305\n",
      "recon_loss 0.16792094707489014\n",
      "13070\n",
      "lse_loss -1.5218191146850586\n",
      "commit_loss 0.012593409977853298\n",
      "recon_loss 0.1629735231399536\n",
      "13071\n",
      "lse_loss -1.5271425247192383\n",
      "commit_loss 0.01223839819431305\n",
      "recon_loss 0.16343241930007935\n",
      "13072\n",
      "lse_loss -1.5127086639404297\n",
      "commit_loss 0.011860760860145092\n",
      "recon_loss 0.17046867311000824\n",
      "13073\n",
      "lse_loss -1.5363669395446777\n",
      "commit_loss 0.009558690711855888\n",
      "recon_loss 0.16051870584487915\n",
      "13074\n",
      "lse_loss -1.542459487915039\n",
      "commit_loss 0.009523731656372547\n",
      "recon_loss 0.1606980711221695\n",
      "13075\n",
      "lse_loss -1.5620946884155273\n",
      "commit_loss 0.00886530987918377\n",
      "recon_loss 0.1693091243505478\n",
      "13076\n",
      "lse_loss -1.5448408126831055\n",
      "commit_loss 0.009745178744196892\n",
      "recon_loss 0.1651303768157959\n",
      "13077\n",
      "lse_loss -1.5757789611816406\n",
      "commit_loss 0.010420572943985462\n",
      "recon_loss 0.16063722968101501\n",
      "13078\n",
      "lse_loss -1.591348648071289\n",
      "commit_loss 0.009781873784959316\n",
      "recon_loss 0.161920428276062\n",
      "13079\n",
      "lse_loss -1.6029696464538574\n",
      "commit_loss 0.009661467745900154\n",
      "recon_loss 0.16691315174102783\n",
      "13080\n",
      "lse_loss -1.6210575103759766\n",
      "commit_loss 0.009674813598394394\n",
      "recon_loss 0.15783657133579254\n",
      "13081\n",
      "lse_loss -1.6114554405212402\n",
      "commit_loss 0.008475721813738346\n",
      "recon_loss 0.1604495793581009\n",
      "13082\n",
      "lse_loss -1.576833724975586\n",
      "commit_loss 0.009075181558728218\n",
      "recon_loss 0.16331890225410461\n",
      "13083\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, latent_temp=1)\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'lse_loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                elif 'commit_loss' in key:\n",
    "                    loss = loss + data[key] * 0\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]        \n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            \n",
    "            log_sigma = model.latent.log_sigma.item()\n",
    "            writer.add_scalar('log_sigma', log_sigma, step)\n",
    "            \n",
    "            usage = ((data['belong'].sum(dim=0) > 0).sum() / hp.M).item()\n",
    "            writer.add_scalar('usage', usage, step)            \n",
    "\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            x = data['x']\n",
    "            y = data['y']\n",
    "            \n",
    "            plot(x)\n",
    "            plot(y)\n",
    "                        \n",
    "            grad = torch.softmax(data['matrix'], dim=0)\n",
    "            grad = grad.data.cpu().numpy()\n",
    "\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            for i in np.random.randint(0, grad.shape[1], size=[10]):\n",
    "                plt.figure(figsize=[18, 1])\n",
    "                plt.plot(grad[:, i])\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "            \n",
    "            e = model.prior.prior.data.cpu().numpy()\n",
    "            z = data['z'].data.cpu().numpy()\n",
    "            t = data['t'].data.cpu().numpy()\n",
    "            plt.figure(figsize=[10, 10])\n",
    "            plt.scatter(e[:, 0], e[:, 1], marker='x', alpha=1.0, color='black')\n",
    "            plt.scatter(z[:, 0], z[:, 1], marker='o', alpha=0.3, c=t, cmap=discrete_cmap(10, 'jet'))\n",
    "            plt.grid()\n",
    "            plt.xlim([-3, 3])\n",
    "            plt.ylim([-3, 3])\n",
    "            plt.show() \n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb82c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1435ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308e82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8a5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
