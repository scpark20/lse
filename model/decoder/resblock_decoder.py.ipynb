{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cdb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_dim, h_dim, kernel_size=1),\n",
    "                                   nn.BatchNorm2d(h_dim),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Conv2d(h_dim, h_dim, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm2d(h_dim),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Conv2d(h_dim, h_dim, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm2d(h_dim),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Conv2d(h_dim, in_dim, kernel_size=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x + self.block(x)\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, size, out_dim, z_dim, n_blocks, h_dims=[32, 64, 128, 256, 512], **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        size = size // 2 ** len(h_dims)\n",
    "        self.size = size\n",
    "        in_dim = h_dims[-1]\n",
    "        self.in_dim = in_dim\n",
    "        self.linear = nn.Linear(z_dim, in_dim*size**2)\n",
    "        \n",
    "        h_dims = h_dims[:-1]\n",
    "        ups = []\n",
    "        blocks = []\n",
    "        for h_dim in h_dims[::-1]:\n",
    "            up = nn.Sequential(nn.ConvTranspose2d(in_dim, h_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                 nn.BatchNorm2d(h_dim),\n",
    "                                 nn.LeakyReLU())\n",
    "            ups.append(up)\n",
    "            block = nn.Sequential(*[ResBlock(h_dim, h_dim) for _ in range(n_blocks)])\n",
    "            blocks.append(block)\n",
    "            in_dim = h_dim\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.out_conv = nn.Sequential(nn.ConvTranspose2d(h_dim, h_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                      nn.BatchNorm2d(h_dim),\n",
    "                                      nn.LeakyReLU(),\n",
    "                                      nn.Conv2d(h_dim, out_dim, kernel_size=3, padding=1),\n",
    "                                      nn.Tanh())\n",
    "        \n",
    "    def forward(self, data, **kwargs):\n",
    "        # x : (b, c, h, w)\n",
    "        \n",
    "        z = data['z']\n",
    "        y = self.linear(z)\n",
    "        y = y.reshape(y.shape[0], self.in_dim, self.size, self.size)\n",
    "        for up, block in zip(self.ups, self.blocks):\n",
    "            y = up(y)\n",
    "            y = block(y)\n",
    "        y = self.out_conv(y)\n",
    "        data['y'] = y\n",
    "        data['recon_loss'] = F.mse_loss(data['y'], data['x'])\n",
    "        return data\n",
    "    \n",
    "    def sample(self, z):\n",
    "        y = self.linear(z)\n",
    "        y = y.reshape(y.shape[0], self.in_dim, self.size, self.size)\n",
    "        for up, block in zip(self.ups, self.blocks):\n",
    "            y = up(y)\n",
    "            y = block(y)\n",
    "        y = self.out_conv(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2ffe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(64, 1, 128, 4)\n",
    "data = {'x': torch.randn(2, 1, 64, 64),\n",
    "        'z': torch.randn(2, 128)}\n",
    "data = decoder(data)\n",
    "print(data['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116dbbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579aa6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
