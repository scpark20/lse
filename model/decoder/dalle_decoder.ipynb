{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7298c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logit_laplace_eps: float = 0.1\n",
    "\n",
    "@attr.s(eq=False)\n",
    "class Conv2d(nn.Module):\n",
    "\tn_in:  int = attr.ib(validator=lambda i, a, x: x >= 1)\n",
    "\tn_out: int = attr.ib(validator=lambda i, a, x: x >= 1)\n",
    "\tkw:    int = attr.ib(validator=lambda i, a, x: x >= 1 and x % 2 == 1)\n",
    "\n",
    "\tuse_float16:   bool         = attr.ib(default=True)\n",
    "\tdevice:        torch.device = attr.ib(default=torch.device('cpu'))\n",
    "\trequires_grad: bool         = attr.ib(default=False)\n",
    "\n",
    "\tdef __attrs_post_init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tw = torch.empty((self.n_out, self.n_in, self.kw, self.kw), dtype=torch.float32,\n",
    "\t\t\tdevice=self.device, requires_grad=self.requires_grad)\n",
    "\t\tw.normal_(std=1 / math.sqrt(self.n_in * self.kw ** 2))\n",
    "\n",
    "\t\tb = torch.zeros((self.n_out,), dtype=torch.float32, device=self.device,\n",
    "\t\t\trequires_grad=self.requires_grad)\n",
    "\t\tself.w, self.b = nn.Parameter(w), nn.Parameter(b)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\tif self.use_float16 and 'cuda' in self.w.device.type:\n",
    "\t\t\tif x.dtype != torch.float16:\n",
    "\t\t\t\tx = x.half()\n",
    "\n",
    "\t\t\tw, b = self.w.half(), self.b.half()\n",
    "\t\telse:\n",
    "\t\t\tif x.dtype != torch.float32:\n",
    "\t\t\t\tx = x.float()\n",
    "\n",
    "\t\t\tw, b = self.w, self.b\n",
    "\n",
    "\t\treturn F.conv2d(x, w, b, padding=(self.kw - 1) // 2)\n",
    "\n",
    "def map_pixels(x: torch.Tensor) -> torch.Tensor:\n",
    "\tif len(x.shape) != 4:\n",
    "\t\traise ValueError('expected input to be 4d')\n",
    "\tif x.dtype != torch.float:\n",
    "\t\traise ValueError('expected input to have type float')\n",
    "\n",
    "\treturn (1 - 2 * logit_laplace_eps) * x + logit_laplace_eps\n",
    "\n",
    "def unmap_pixels(x: torch.Tensor) -> torch.Tensor:\n",
    "\tif len(x.shape) != 4:\n",
    "\t\traise ValueError('expected input to be 4d')\n",
    "\tif x.dtype != torch.float:\n",
    "\t\traise ValueError('expected input to have type float')\n",
    "\n",
    "\treturn torch.clamp((x - logit_laplace_eps) / (1 - 2 * logit_laplace_eps), 0, 1)\n",
    "\n",
    "import attr\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections  import OrderedDict\n",
    "from functools    import partial\n",
    "\n",
    "@attr.s(eq=False, repr=False)\n",
    "class DecoderBlock(nn.Module):\n",
    "\tn_in:     int = attr.ib(validator=lambda i, a, x: x >= 1)\n",
    "\tn_out:    int = attr.ib(validator=lambda i, a, x: x >= 1 and x % 4 ==0)\n",
    "\tn_layers: int = attr.ib(validator=lambda i, a, x: x >= 1)\n",
    "\n",
    "\tdevice:        torch.device = attr.ib(default=None)\n",
    "\trequires_grad: bool         = attr.ib(default=False)\n",
    "\n",
    "\tdef __attrs_post_init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.n_hid = self.n_out // 4\n",
    "\t\tself.post_gain = 1 / (self.n_layers ** 2)\n",
    "\n",
    "\t\tmake_conv     = partial(Conv2d, device=self.device, requires_grad=self.requires_grad)\n",
    "\t\tself.id_path  = make_conv(self.n_in, self.n_out, 1) if self.n_in != self.n_out else nn.Identity()\n",
    "\t\tself.res_path = nn.Sequential(OrderedDict([\n",
    "\t\t\t\t('relu_1', nn.ReLU()),\n",
    "\t\t\t\t('conv_1', make_conv(self.n_in,  self.n_hid, 1)),\n",
    "\t\t\t\t('relu_2', nn.ReLU()),\n",
    "\t\t\t\t('conv_2', make_conv(self.n_hid, self.n_hid, 3)),\n",
    "\t\t\t\t('relu_3', nn.ReLU()),\n",
    "\t\t\t\t('conv_3', make_conv(self.n_hid, self.n_hid, 3)),\n",
    "\t\t\t\t('relu_4', nn.ReLU()),\n",
    "\t\t\t\t('conv_4', make_conv(self.n_hid, self.n_out, 3)),]))\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\treturn self.id_path(x) + self.post_gain * self.res_path(x)\n",
    "\n",
    "@attr.s(eq=False, repr=False)\n",
    "class DALLEDecoder(nn.Module):\n",
    "\tgroup_count:     int = 4\n",
    "\tn_init:          int = attr.ib(default=128,  validator=lambda i, a, x: x >= 8)\n",
    "\tn_hid:           int = attr.ib(default=256,  validator=lambda i, a, x: x >= 64)\n",
    "\tn_blk_per_group: int = attr.ib(default=2,    validator=lambda i, a, x: x >= 1)\n",
    "\toutput_channels: int = attr.ib(default=3,    validator=lambda i, a, x: x >= 1)\n",
    "\tvocab_size:      int = attr.ib(default=8192, validator=lambda i, a, x: x >= 512)\n",
    "\n",
    "\tdevice:              torch.device = attr.ib(default=torch.device('cpu'))\n",
    "\trequires_grad:       bool         = attr.ib(default=False)\n",
    "\tuse_mixed_precision: bool         = attr.ib(default=True)\n",
    "\n",
    "\tdef __attrs_post_init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tblk_range  = range(self.n_blk_per_group)\n",
    "\t\tn_layers   = self.group_count * self.n_blk_per_group\n",
    "\t\tmake_conv  = partial(Conv2d, device=self.device, requires_grad=self.requires_grad)\n",
    "\t\tmake_blk   = partial(DecoderBlock, n_layers=n_layers, device=self.device,\n",
    "\t\t\t\trequires_grad=self.requires_grad)\n",
    "\n",
    "\t\tself.blocks = nn.Sequential(OrderedDict([\n",
    "\t\t\t('input', make_conv(self.vocab_size, self.n_init, 1, use_float16=False)),\n",
    "\t\t\t('group_1', nn.Sequential(OrderedDict([\n",
    "\t\t\t\t*[(f'block_{i + 1}', make_blk(self.n_init if i == 0 else 8 * self.n_hid, 8 * self.n_hid)) for i in blk_range],\n",
    "\t\t\t\t('upsample', nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "\t\t\t]))),\n",
    "\t\t\t('group_2', nn.Sequential(OrderedDict([\n",
    "\t\t\t\t*[(f'block_{i + 1}', make_blk(8 * self.n_hid if i == 0 else 4 * self.n_hid, 4 * self.n_hid)) for i in blk_range],\n",
    "\t\t\t\t('upsample', nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "\t\t\t]))),\n",
    "\t\t\t('group_3', nn.Sequential(OrderedDict([\n",
    "\t\t\t\t*[(f'block_{i + 1}', make_blk(4 * self.n_hid if i == 0 else 2 * self.n_hid, 2 * self.n_hid)) for i in blk_range],\n",
    "\t\t\t\t('upsample', nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "\t\t\t]))),\n",
    "\t\t\t('group_4', nn.Sequential(OrderedDict([\n",
    "\t\t\t\t*[(f'block_{i + 1}', make_blk(2 * self.n_hid if i == 0 else 1 * self.n_hid, 1 * self.n_hid)) for i in blk_range],\n",
    "\t\t\t]))),\n",
    "\t\t\t('output', nn.Sequential(OrderedDict([\n",
    "\t\t\t\t('relu', nn.ReLU()),\n",
    "\t\t\t\t('conv', make_conv(1 * self.n_hid, self.output_channels, 1)),\n",
    "\t\t\t]))),\n",
    "\t\t]))\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\tif len(x.shape) != 4:\n",
    "\t\t\traise ValueError(f'input shape {x.shape} is not 4d')\n",
    "\t\tif x.shape[1] != self.vocab_size:\n",
    "\t\t\traise ValueError(f'input has {x.shape[1]} channels but model built for {self.vocab_size}')\n",
    "\t\tif x.dtype != torch.float32:\n",
    "\t\t\traise ValueError('input must have dtype torch.float32')\n",
    "\n",
    "\t\treturn self.blocks(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=512, **kwargs):\n",
    "        super().__init__()\n",
    "        self.decoder = DALLEDecoder(vocab_size=z_dim)\n",
    "        \n",
    "    def forward(self, data, **kwargs):\n",
    "        # x : (b, c, h, w)\n",
    "        data['y'] = self.decoder(data['z'])\n",
    "        data['recon_loss'] = F.mse_loss(data['y'], data['x'])\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fb7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256]) tensor(1.3670, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = {'z': torch.randn(2, 512, 32, 32),\n",
    "        'x': torch.randn(2, 3, 256, 256)}\n",
    "data = Decoder()(data)\n",
    "print(data['y'].shape, data['recon_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72370e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f5623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0b10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b93ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
