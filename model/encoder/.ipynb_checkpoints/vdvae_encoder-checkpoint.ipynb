{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b78d2ac2-2969-4f32-85e2-36563b9949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from vae_helpers import get_1x1, get_3x3, HModule\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da17ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_layer_string(s):\n",
    "    layers = []\n",
    "    for ss in s.split(','):\n",
    "        if 'x' in ss:\n",
    "            res, num = ss.split('x')\n",
    "            count = int(num)\n",
    "            layers += [(int(res), None) for _ in range(count)]\n",
    "        elif 'm' in ss:\n",
    "            res, mixin = [int(a) for a in ss.split('m')]\n",
    "            layers.append((res, mixin))\n",
    "        elif 'd' in ss:\n",
    "            res, down_rate = [int(a) for a in ss.split('d')]\n",
    "            layers.append((res, down_rate))\n",
    "        else:\n",
    "            res = int(ss)\n",
    "            layers.append((res, None))\n",
    "    return layers\n",
    "\n",
    "\n",
    "def pad_channels(t, width):\n",
    "    d1, d2, d3, d4 = t.shape\n",
    "    empty = torch.zeros(d1, width, d3, d4, device=t.device)\n",
    "    empty[:, :d2, :, :] = t\n",
    "    return empty\n",
    "\n",
    "\n",
    "def get_width_settings(width, s):\n",
    "    mapping = defaultdict(lambda: width)\n",
    "    if s:\n",
    "        s = s.split(',')\n",
    "        for ss in s:\n",
    "            k, v = ss.split(':')\n",
    "            mapping[int(k)] = int(v)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8f4f30a-f512-4cd6-88f8-f61a0701273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_width, middle_width, out_width,\n",
    "                 down_rate=None, residual=False, use_3x3=True, zero_last=False):\n",
    "        super().__init__()\n",
    "        self.down_rate = down_rate\n",
    "        self.residual = residual\n",
    "        self.c1 = get_1x1(in_width, middle_width)\n",
    "        self.c2 = get_3x3(middle_width, middle_width) if use_3x3 else get_1x1(middle_width, middle_width)\n",
    "        self.c3 = get_3x3(middle_width, middle_width) if use_3x3 else get_1x1(middle_width, middle_width)\n",
    "        self.c4 = get_1x1(middle_width, out_width, zero_weights=zero_last)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xhat = self.c1(F.gelu(x))\n",
    "        xhat = self.c2(F.gelu(xhat))\n",
    "        xhat = self.c3(F.gelu(xhat))\n",
    "        xhat = self.c4(F.gelu(xhat))        \n",
    "        out = x + xhat if self.residual else xhat\n",
    "        if self.down_rate is not None:\n",
    "            out = F.avg_pool2d(out, kernel_size=self.down_rate, stride=self.down_rate)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c285667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "block = Block(64, 128, 64, down_rate=2, residual=True)\n",
    "x = torch.randn(2, 64, 128, 128)\n",
    "y = block(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf616bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VDEncoder(HModule):\n",
    "    def build(self):\n",
    "        H = self.H\n",
    "        self.in_conv = get_3x3(H.image_channels, H.width)\n",
    "        self.widths = get_width_settings(H.width, H.custom_width_str)\n",
    "        enc_blocks = []\n",
    "        blockstr = parse_layer_string(H.enc_blocks)\n",
    "        for res, down_rate in blockstr:\n",
    "            use_3x3 = res > 2  # Don't use 3x3s for 1x1, 2x2 patches\n",
    "            enc_blocks.append(Block(self.widths[res], int(self.widths[res] * H.bottleneck_multiple), self.widths[res], down_rate=down_rate, residual=True, use_3x3=use_3x3))\n",
    "        n_blocks = len(blockstr)\n",
    "        for b in enc_blocks:\n",
    "            b.c4.weight.data *= np.sqrt(1 / n_blocks)\n",
    "        self.enc_blocks = nn.ModuleList(enc_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "        activations = {}\n",
    "        activations[x.shape[2]] = x\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            res = x.shape[2]\n",
    "            x = x if x.shape[1] == self.widths[res] else pad_channels(x, self.widths[res])\n",
    "            activations[res] = x\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4308af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.encoder = VDEncoder(H)\n",
    "        \n",
    "    def forward(self, data, **kwargs):\n",
    "        # x : (b, c, h, w)\n",
    "        data['activations'] = self.encoder(data['x'])\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "929d8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "H = EasyDict()\n",
    "H.image_channels = 3\n",
    "H.width = 384\n",
    "H.custom_width_str = \"\"\n",
    "H.enc_blocks = \"32x11,32d2,16x6,16d2,8x6,8d2,4x3,4d4,1x3\"\n",
    "H.bottleneck_multiple = 0.25\n",
    "encoder = Encoder(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3de6011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 torch.Size([2, 384, 64, 64])\n",
      "32 torch.Size([2, 384, 32, 32])\n",
      "16 torch.Size([2, 384, 16, 16])\n",
      "8 torch.Size([2, 384, 8, 8])\n",
      "2 torch.Size([2, 384, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "data = {'x': torch.randn(2, 3, 64, 64)}\n",
    "data = encoder(data)\n",
    "for key in data['activations'].keys():\n",
    "    print(key, data['activations'][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee7e6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.6021728515625"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 * 1024)\n",
    "\n",
    "get_size(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aa9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ded80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
