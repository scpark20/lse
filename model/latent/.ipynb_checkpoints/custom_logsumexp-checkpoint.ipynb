{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3774594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 1],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 0, 0, 0]])\n",
      "tensor([[ 1.4569, -0.0574, -0.7526, -0.4921],\n",
      "        [-1.2380,  2.0233, -0.4984,  1.9862],\n",
      "        [ 0.0494,  0.9031,  1.1277,  0.2750]], requires_grad=True)\n",
      "tensor([[  -inf, 0.9426, 0.2474, 0.5079],\n",
      "        [  -inf, 3.0233,   -inf, 2.9862],\n",
      "        [1.0494,   -inf,   -inf,   -inf]])\n",
      "tensor([[0.0000, 0.4659, 0.2325, 0.3016],\n",
      "        [0.0000, 0.5093, 0.0000, 0.4907],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CustomLogSumExp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, belong=None, temp=1):\n",
    "        # input : (M, N)\n",
    "        # belong : (M, N)\n",
    "        \n",
    "        ctx.temp = temp\n",
    "        # (M, 1)\n",
    "        output = torch.logsumexp(input, dim=1, keepdim=True)\n",
    "        ctx.save_for_backward(input, output, belong)\n",
    "        return output.squeeze(1)  # output을 반환할 때는 차원을 줄입니다.\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        temp = ctx.temp\n",
    "        # (M, N), (M, 1), (M, N)\n",
    "        input, output, belong = ctx.saved_tensors\n",
    "        # softmax 함수를 사용하여 그래디언트 계산을 수행합니다.\n",
    "        # (M, N)\n",
    "        if belong is None:\n",
    "            softmax_result = torch.exp(input - output)\n",
    "        else:\n",
    "            inner_value = input * belong + torch.where(belong == 0, -np.inf, belong)\n",
    "            softmax_result = torch.softmax(inner_value, dim=1)\n",
    "        grad_input = softmax_result * grad_output.unsqueeze(1)\n",
    "        return grad_input, None\n",
    "\n",
    "# 함수를 사용하려면 apply 메서드를 사용하고, dim 매개변수를 전달합니다.\n",
    "input = torch.randn(3, 4, requires_grad=True)\n",
    "belong = torch.randint(0, 2, size=[*input.shape])\n",
    "output = CustomLogSumExp.apply(input, belong)\n",
    "output.backward(torch.ones_like(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e600381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [-inf, -inf, 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 2, size=(2, 3))\n",
    "torch.where(x == 1, -np.inf, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a79478cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.420680743952364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1dadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
