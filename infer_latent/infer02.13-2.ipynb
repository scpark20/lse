{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9478b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc71139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 13 20:05:47 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 32%   44C    P5              75W / 200W |     11MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "| 34%   65C    P2             194W / 200W |  23499MiB / 24564MiB |     86%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    1   N/A  N/A      1050      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1343      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "|    1   N/A  N/A      4804      C   ...cpark/anaconda3/envs/ste/bin/python    23464MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd882924",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "410d14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_size = 256\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 8\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 512\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x21,64m32,64x13,128m64,128x7,256m128\"\n",
    "hp.enc_blocks = \"256x3,256d2,128x8,128d2,64x12,64d2,32x17,32d2,16x7,16d2,8x5,8d2,4x5,4d4,1x4\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 1e-4\n",
    "\n",
    "# Diffusion\n",
    "hp.scheduler = DDPMScheduler()\n",
    "hp.scheduler.set_timesteps(10)\n",
    "hp.diff_middle_width = 128\n",
    "hp.diff_residual = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e9907",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7fe716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae_latent import Model as VAE\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_diffusion_decoder import Decoder\n",
    "from model.loss.dmol import Loss\n",
    "\n",
    "from model.main.latent_diffusion import Model as LD\n",
    "from model.latent_diffusion.denorm_latent_diffusion import LatentDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34728634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "ld = LD(LatentDiffusion(hp)).to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa3e972f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "draw_samples_list = []\n",
    "for i in range(len(ld.latent_diffusion.backbones)):\n",
    "    def draw_samples(pm, pv):\n",
    "        latents = torch.randn_like(pm) * hp.scheduler.init_noise_sigma\n",
    "        for t in hp.scheduler.timesteps:\n",
    "            inp = hp.scheduler.scale_model_input(latents, t)\n",
    "            t_tensor = torch.ones((len(inp),)).to(device) * t\n",
    "            inp = inp * torch.exp(pv) + pm\n",
    "            pred = ld.latent_diffusion.backbones[i](inp, t_tensor)\n",
    "            pred = (pred - pm) / torch.exp(pv)\n",
    "            latents = hp.scheduler.step(pred, t, latents)['prev_sample']\n",
    "        return latents * torch.exp(pv) + pm\n",
    "    draw_samples_list.append(draw_samples)\n",
    "    \n",
    "hp.draw_samples_list = draw_samples_list\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0f64416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72570d1",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3660e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data/save/lse/train_latent/train02.13-2/save_10000'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "ld.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d2e2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/data/checkpoint/ffhq256-iter-1700000-model-ema.th'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model_state_dict = vae.state_dict()\n",
    "for key in checkpoint.keys():\n",
    "    if key.startswith('encoder'):\n",
    "        model_key = 'encoder.' + key\n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "    if key.startswith('decoder'):\n",
    "        if key.startswith('decoder.out_net'):\n",
    "            model_key = 'loss.' + key[8:]\n",
    "        else:\n",
    "            model_key = 'decoder.' + key\n",
    "            \n",
    "        if model_key in model_state_dict:\n",
    "            model_state_dict[model_key] = checkpoint[key]\n",
    "        else:\n",
    "            print(model_key)\n",
    "            \n",
    "vae.load_state_dict(model_state_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "907dfdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:00, 82.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    samples = vae.sample(5)\n",
    "    print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(samples):\n",
    "    import matplotlib.pyplot as plt\n",
    "    N = len(samples)\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(len(samples)):\n",
    "        plt.subplot(1, N, i+1)\n",
    "        plt.imshow(samples[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "show_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314392d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ec17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082f026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
