{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba321e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 12 04:29:55 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| 30%   27C    P8    14W / 230W |      8MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   39C    P2    87W / 230W |   4186MiB / 24564MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 30%   30C    P0    56W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    20W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    Off  | 00000000:89:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    18W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    Off  | 00000000:8A:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    19W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A5000    Off  | 00000000:8B:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    19W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A5000    Off  | 00000000:8C:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    18W / 230W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   1980319      C   ...onda3/envs/ste/bin/python     4178MiB |\n",
      "|    2   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      4537      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc4b38",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ffa1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_latent_dec import Model\n",
    "from model.encoder.conv2d_vae_encoder import Encoder\n",
    "from model.latent_layer.sampling_uniform_lse_latent_layer import LatentLayer\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bb8ad",
   "metadata": {},
   "source": [
    "\n",
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e4a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 1\n",
    "hp.out_dim = 1\n",
    "hp.z_dim = 2\n",
    "hp.h_dims = [32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b85be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 6.0202789306640625\n",
      "encoder.convs 5.989013671875\n",
      "encoder.linear 0.0312652587890625\n",
      "latent_layer 3.814697265625e-06\n",
      "decoder 6.044322967529297\n",
      "decoder.linear 0.0234375\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = Model(Encoder(**hp), LatentLayer(**hp), Decoder(**hp))\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6751277",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15da5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 113836\r\n",
      "-rw-rw-r-- 1 scpark scpark  2474244  1월 12 04:15 events.out.tfevents.1704999236.GPUSVR01\r\n",
      "-rw-rw-r-- 1 scpark scpark 38028893  1월 12 04:09 save_20000\r\n",
      "-rw-rw-r-- 1 scpark scpark 38028893  1월 12 04:01 save_10000\r\n",
      "-rw-rw-r-- 1 scpark scpark 38023101  1월 12 03:54 save_0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train01.12-2/'\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, net_g, _, opt_g, _ = load(save_dir, 0, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bca073",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fb4843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations applied on each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the image to 32x32\n",
    "    transforms.ToTensor(),         # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5), (0.5)) \n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=2048, shuffle=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801de5f",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5660006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4844df5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1472acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(_x[i, 0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f211a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3251\n",
      "lse_loss -3.992061138153076\n",
      "recon_loss 0.20734600722789764\n",
      "3252\n",
      "lse_loss -3.9708447456359863\n",
      "recon_loss 0.18974122405052185\n",
      "3253\n",
      "lse_loss -3.921410083770752\n",
      "recon_loss 0.1887613981962204\n",
      "3254\n",
      "lse_loss -3.829550266265869\n",
      "recon_loss 0.18680068850517273\n",
      "3255\n",
      "lse_loss -3.931544065475464\n",
      "recon_loss 0.19385115802288055\n",
      "3256\n",
      "lse_loss -3.7435007095336914\n",
      "recon_loss 0.19512677192687988\n",
      "3257\n",
      "lse_loss -3.7199575901031494\n",
      "recon_loss 0.1870589703321457\n",
      "3258\n",
      "lse_loss -3.8041672706604004\n",
      "recon_loss 0.19290976226329803\n",
      "3259\n",
      "lse_loss -3.5732812881469727\n",
      "recon_loss 0.19317570328712463\n",
      "3260\n",
      "lse_loss -3.6299197673797607\n",
      "recon_loss 0.1932142972946167\n",
      "3261\n",
      "lse_loss -3.5215415954589844\n",
      "recon_loss 0.18245908617973328\n",
      "3262\n",
      "lse_loss -3.513749837875366\n",
      "recon_loss 0.19263462722301483\n",
      "3263\n",
      "lse_loss -3.379891872406006\n",
      "recon_loss 0.18924622237682343\n",
      "3264\n",
      "lse_loss -3.610766649246216\n",
      "recon_loss 0.1918032020330429\n",
      "3265\n",
      "lse_loss -3.368816614151001\n",
      "recon_loss 0.19081656634807587\n",
      "3266\n",
      "lse_loss -3.3861234188079834\n",
      "recon_loss 0.1879027783870697\n",
      "3267\n",
      "lse_loss -3.546405553817749\n",
      "recon_loss 0.17948779463768005\n",
      "3268\n",
      "lse_loss -3.402716636657715\n",
      "recon_loss 0.18215736746788025\n",
      "3269\n",
      "lse_loss -3.192045211791992\n",
      "recon_loss 0.18667124211788177\n",
      "3270\n",
      "lse_loss -3.497535228729248\n",
      "recon_loss 0.19212374091148376\n",
      "3271\n",
      "lse_loss -3.20721173286438\n",
      "recon_loss 0.18074586987495422\n",
      "3272\n",
      "lse_loss -3.217926502227783\n",
      "recon_loss 0.1917084902524948\n",
      "3273\n",
      "lse_loss -3.273148775100708\n",
      "recon_loss 0.19652996957302094\n",
      "3274\n",
      "lse_loss -3.420142412185669\n",
      "recon_loss 0.1837289035320282\n",
      "3275\n",
      "lse_loss -2.832726240158081\n",
      "recon_loss 0.18344902992248535\n",
      "3276\n",
      "lse_loss -3.185903787612915\n",
      "recon_loss 0.18909518420696259\n",
      "3277\n",
      "lse_loss -3.3717284202575684\n",
      "recon_loss 0.20127980411052704\n",
      "3278\n",
      "lse_loss -3.439361095428467\n",
      "recon_loss 0.19761419296264648\n",
      "3279\n",
      "lse_loss -3.064516544342041\n",
      "recon_loss 0.1839752197265625\n",
      "3280\n",
      "lse_loss -3.2592074871063232\n",
      "recon_loss 0.18119236826896667\n",
      "3281\n",
      "lse_loss -3.269728422164917\n",
      "recon_loss 0.1846434473991394\n",
      "3282\n",
      "lse_loss -3.2750189304351807\n",
      "recon_loss 0.1844780147075653\n",
      "3283\n",
      "lse_loss -3.3746836185455322\n",
      "recon_loss 0.18827150762081146\n",
      "3284\n",
      "lse_loss -3.227916955947876\n",
      "recon_loss 0.19053272902965546\n",
      "3285\n",
      "lse_loss -3.14528751373291\n",
      "recon_loss 0.19103334844112396\n",
      "3286\n",
      "lse_loss -3.283036470413208\n",
      "recon_loss 0.17636875808238983\n",
      "3287\n",
      "lse_loss -3.2941396236419678\n",
      "recon_loss 0.1829773634672165\n",
      "3288\n",
      "lse_loss -3.2855353355407715\n",
      "recon_loss 0.19253823161125183\n",
      "3289\n",
      "lse_loss -3.2473881244659424\n",
      "recon_loss 0.1843574494123459\n",
      "3290\n",
      "lse_loss -3.1528425216674805\n",
      "recon_loss 0.18645761907100677\n",
      "3291\n",
      "lse_loss -3.423717498779297\n",
      "recon_loss 0.17977580428123474\n",
      "3292\n",
      "lse_loss -3.119351387023926\n",
      "recon_loss 0.18116837739944458\n",
      "3293\n",
      "lse_loss -3.229189395904541\n",
      "recon_loss 0.17693309485912323\n",
      "3294\n",
      "lse_loss -3.225842237472534\n",
      "recon_loss 0.19052010774612427\n",
      "3295\n",
      "lse_loss -3.1953318119049072\n",
      "recon_loss 0.17866763472557068\n",
      "3296\n",
      "lse_loss -3.2718002796173096\n",
      "recon_loss 0.19197282195091248\n",
      "3297\n",
      "lse_loss -3.324016571044922\n",
      "recon_loss 0.1818358302116394\n",
      "3298\n",
      "lse_loss -3.246389627456665\n",
      "recon_loss 0.18058854341506958\n",
      "3299\n",
      "lse_loss -3.1614534854888916\n",
      "recon_loss 0.18926507234573364\n",
      "3300\n",
      "lse_loss -3.1333956718444824\n",
      "recon_loss 0.18467985093593597\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        data = preprocess(batch)\n",
    "        \n",
    "        # Forward\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        data = model(data, M=10000)\n",
    "        \n",
    "        # Backward\n",
    "        loss = 0\n",
    "        for key in data.keys():\n",
    "            if 'lse_loss' in key:\n",
    "                loss = loss + data[key] * 1e-4\n",
    "                writer.add_scalar(key, data[key].item(), step)\n",
    "                print(key, data[key].item())\n",
    "            elif 'loss' in key:\n",
    "                loss = loss + data[key]\n",
    "                writer.add_scalar(key, data[key].item(), step)\n",
    "                print(key, data[key].item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            batch = next(iter(test_loader))\n",
    "            data = preprocess(batch)\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, M=1000)\n",
    "                \n",
    "            print('z_logvar :', model.latent_layer.z_logvar)\n",
    "            \n",
    "            plot(data['x'])\n",
    "            plot(data['y'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = (torch.rand(10, hp.z_dim)*2-1).to(device)\n",
    "                y = model.sample(z)\n",
    "                plot(y)\n",
    "                \n",
    "            import matplotlib.pyplot as plt\n",
    "            _z = data['z'].data.cpu().numpy()\n",
    "            plt.scatter(_z[:, 0], _z[:, 1], c=data['t'].data.cpu().numpy(), cmap=discrete_cmap(10, 'jet'))\n",
    "            plt.grid()\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "        \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167f2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
