{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69634396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b797034a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 11 18:35:10 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 39%   68C    P2             248W / 450W |  21010MiB / 24564MiB |     77%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "| 44%   70C    P2             182W / 450W |  12364MiB / 24564MiB |     43%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1185      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    0   N/A  N/A      2664      C   ...cpark/anaconda3/envs/ste/bin/python     5244MiB |\r\n",
      "|    0   N/A  N/A      2807      C   ...cpark/anaconda3/envs/ste/bin/python     5242MiB |\r\n",
      "|    0   N/A  N/A      2840      C   ...cpark/anaconda3/envs/ste/bin/python     5246MiB |\r\n",
      "|    0   N/A  N/A      2873      C   ...cpark/anaconda3/envs/ste/bin/python     5250MiB |\r\n",
      "|    1   N/A  N/A      1185      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1883      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "|    1   N/A  N/A      2906      C   ...cpark/anaconda3/envs/ste/bin/python     5254MiB |\r\n",
      "|    1   N/A  N/A      4685      C   ...cpark/anaconda3/envs/ste/bin/python     5282MiB |\r\n",
      "|    1   N/A  N/A      4740      C   ...cpark/anaconda3/envs/ste/bin/python     1786MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678078e5",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee88fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_dec import Model\n",
    "from model.encoder.conv2d_encoder import Encoder\n",
    "from model.prior.uniform_prior import Prior\n",
    "from model.latent.bottleneck_swae_latent import Latent\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29b2fd",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a918a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 1\n",
    "hp.out_dim = 1\n",
    "hp.z_dim = 512\n",
    "hp.h_dims = [32, 64, 128, 256, 512]\n",
    "hp.M = None\n",
    "hp.N = 256\n",
    "hp.z_activation = F.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58159d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 9.990966796875\n",
      "encoder.convs 5.989013671875\n",
      "encoder.linear 4.001953125\n",
      "prior 0.0\n",
      "latent 0.0\n",
      "decoder 10.028697967529297\n",
      "decoder.linear 4.0078125\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(1):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6d09e",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e311a4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124148\r\n",
      "-rw-rw-r-- 1 scpark scpark  1018959  2월 11 18:35 events.out.tfevents.1707643405.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark 63053908  2월 11 18:34 save_10000\r\n",
      "-rw-rw-r-- 1 scpark scpark 63048044  2월 11 18:23 save_0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train02.11-6/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, models, opt_g = load(save_dir, 0, models, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc4c57",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473a67f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations applied on each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the image to 32x32\n",
    "    transforms.ToTensor(),         # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5), (0.5)) \n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=hp.N, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=2048, shuffle=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8305996",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbaad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b8440",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc24f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(_x[i, 0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec53dd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fcad918e3f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scpark/anaconda3/envs/ste/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m model(data, M\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mM)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m plot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     _x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, M=hp.M)\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'kl_loss' in key:\n",
    "                    loss = loss + data[key] * 0.00025\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                        \n",
    "                elif 'wise_min_loss' in key:\n",
    "                    loss = loss + data[key] * 1e+4\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                        \n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            batch = next(iter(test_loader))\n",
    "            data = preprocess(batch)\n",
    "            \n",
    "            model = model_list[0]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, M=hp.M)\n",
    "            \n",
    "            plot(data['x'])\n",
    "            plot(data['y'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = (torch.rand(10, hp.z_dim)*2-1).to(device)\n",
    "                y = model.sample(z)\n",
    "                plot(y)\n",
    "                \n",
    "            import matplotlib.pyplot as plt\n",
    "            _z = data['z'].data.cpu().numpy()\n",
    "            plt.scatter(_z[:, 0], _z[:, 1], c=data['t'].data.cpu().numpy(), cmap=discrete_cmap(10, 'jet'))\n",
    "            plt.grid()\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            \n",
    "            _z = data['z'].data.cpu().numpy()\n",
    "\n",
    "            plt.figure(figsize=[10, 10])\n",
    "            for i in range(8):\n",
    "                plt.subplot(4, 4, i+1)\n",
    "                plt.scatter(_z[:, i*2], _z[:, i*2+1], alpha=0.1)\n",
    "                plt.grid()\n",
    "                plt.xlim([-1, 1])\n",
    "                plt.ylim([-1, 1])\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fcfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "for i in range(8):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.scatter(_z[:, i*2], _z[:, i*2+1], alpha=0.1)\n",
    "    plt.grid()\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a14eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a27910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701067d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
