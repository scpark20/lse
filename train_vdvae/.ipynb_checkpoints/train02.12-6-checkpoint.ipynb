{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba202ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 12 18:44:31 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\n",
      "| 32%   54C    P0              88W / 450W |     11MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\n",
      "| 31%   49C    P8              32W / 450W |     28MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                            9MiB |\n",
      "|    1   N/A  N/A      1324      G   /usr/bin/gnome-shell                          8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d51ab",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac98774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 32\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 384\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x1,4m1,4x1,8m4,8x1,16m8,16x1,32m16,32x1\"\n",
    "hp.enc_blocks = \"32x1,32d2,16x1,16d2,8x1,8d2,4x1,4d4,1x1\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 0.0002\n",
    "hp.wd = 0.01\n",
    "hp.adam_beta1 = 0.9\n",
    "hp.adam_beta2 = 0.9\n",
    "hp.warmup_iters = 100\n",
    "hp.ema_rate = 0.9999\n",
    "hp.grad_clip = 200.0\n",
    "hp.skip_threshold = 400.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777903",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b84157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae import Model\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_bottleneck_gumbel_swae_decoder import Decoder\n",
    "from model.loss.dmol_swae_mask import Loss\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c033d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 7.7281494140625\n",
      "decoder 25.4820556640625\n",
      "loss 0.1468658447265625\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = Model(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "ema_model = None\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=hp.wd, lr=hp.lr, betas=(hp.adam_beta1, hp.adam_beta2))\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 1 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d4c2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3ac36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 568660\r\n",
      "-rw-rw-r-- 1 scpark scpark      7150  2월 12 18:44 events.out.tfevents.1707731027.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark 105313502  2월 12 18:43 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark     19030  2월 12 18:43 events.out.tfevents.1707730922.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark       166  2월 12 18:41 events.out.tfevents.1707730894.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark       166  2월 12 18:41 events.out.tfevents.1707730774.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark      2695  2월 12 18:38 events.out.tfevents.1707730570.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark      8095  2월 12 18:36 events.out.tfevents.1707730517.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     18220  2월 12 18:35 events.out.tfevents.1707730291.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark      7960  2월 12 18:31 events.out.tfevents.1707730238.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark      4180  2월 12 18:30 events.out.tfevents.1707730203.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     10120  2월 12 18:29 events.out.tfevents.1707730136.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     46705  2월 12 18:28 events.out.tfevents.1707729861.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark        40  2월 12 18:24 events.out.tfevents.1707729835.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     17545  2월 12 18:23 events.out.tfevents.1707729722.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     60475  2월 12 18:21 events.out.tfevents.1707729368.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark      8230  2월 12 18:16 events.out.tfevents.1707729309.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     35230  2월 12 18:15 events.out.tfevents.1707729101.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     14440  2월 12 18:11 events.out.tfevents.1707729009.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     14980  2월 12 18:10 events.out.tfevents.1707728914.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark    114196  2월 12 18:06 events.out.tfevents.1707728201.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark       166  2월 12 17:56 events.out.tfevents.1707728139.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark     47110  2월 12 17:17 events.out.tfevents.1707724769.scpark-X299-WU8\r\n",
      "-rw-rw-r-- 1 scpark scpark 476472578  2월 12 17:17 save_3487\r\n",
      "-rw-rw-r-- 1 scpark scpark       826  2월 12 16:59 events.out.tfevents.1707724716.scpark-X299-WU8\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/lse/train_vdvae/train02.12-6/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, optimizer = load(save_dir, 60000, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282214",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING TEST\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa334130e00>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.vdvae_data import set_up_data\n",
    "\n",
    "hp, data_train, data_valid_or_test, preprocess_fn = set_up_data(hp)\n",
    "hp.image_size = 32\n",
    "train_loader = DataLoader(data_train, batch_size=hp.n_batch, drop_last=True, pin_memory=True)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98a82",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8269c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from util.train_helpers import update_ema\n",
    "\n",
    "def training_step(H, data_input, target, model, ema_model, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    data = {'x': data_input,\n",
    "            'x_target': target}\n",
    "    stats = model.forward(data, mask_loss_weight=1)\n",
    "    stats['elbo'].backward()\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), H.grad_clip).item()\n",
    "    distortion_nans = torch.isnan(stats['distortion']).sum()\n",
    "    rate_nans = torch.isnan(stats['rate']).sum()\n",
    "    stats.update(dict(rate_nans=0 if rate_nans == 0 else 1, distortion_nans=0 if distortion_nans == 0 else 1))\n",
    "\n",
    "    skipped_updates = 1\n",
    "    # only update if no rank has a nan and if the grad norm is below a specific threshold\n",
    "    if stats['distortion_nans'] == 0 and stats['rate_nans'] == 0 and (H.skip_threshold == -1 or grad_norm < H.skip_threshold):\n",
    "        optimizer.step()\n",
    "        skipped_updates = 0\n",
    "        if ema_model is not None:\n",
    "            update_ema(model, ema_model, H.ema_rate)\n",
    "\n",
    "    stats.update(skipped_updates=skipped_updates, grad_norm=grad_norm)\n",
    "    return stats\n",
    "\n",
    "def show_samples(model, N):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        samples = model.sample(N)\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(len(samples)):\n",
    "        plt.subplot(1, N, i+1)\n",
    "        plt.imshow(samples[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97870d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8960 elbo 3.9357001781463623\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8970 elbo 3.960400104522705\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8980 elbo 3.866349697113037\n",
      "mask loss : tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8990 elbo 4.047083377838135\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mask loss : tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m data_input \u001b[38;5;241m=\u001b[39m data_input\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melbo\u001b[39m\u001b[38;5;124m'\u001b[39m, stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melbo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(H, data_input, target, model, ema_model, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: data_input,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_target\u001b[39m\u001b[38;5;124m'\u001b[39m: target}\n\u001b[1;32m      9\u001b[0m stats \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(data, mask_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melbo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), H\u001b[38;5;241m.\u001b[39mgrad_clip)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     12\u001b[0m distortion_nans \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistortion\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/envs/ste/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ste/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "resize = transforms.Resize((hp.image_size, hp.image_size))\n",
    "\n",
    "while True:\n",
    "    for x in train_loader:\n",
    "        x[0] = resize(x[0].permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        data_input = data_input.to(device)\n",
    "        target = target.to(device)\n",
    "        stats = training_step(hp, data_input, target, model, ema_model, optimizer)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, 'elbo', stats['elbo'].item())\n",
    "            writer.add_scalar('elbo', stats['elbo'].item(), step)\n",
    "            writer.add_scalar('distortion', stats['distortion'].item(), step)\n",
    "            writer.add_scalar('rate', stats['rate'].item(), step)\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            display.clear_output()\n",
    "            show_samples(model, 10)\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, optimizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dec_block in model.decoder.decoder.dec_blocks:\n",
    "    probs = torch.sigmoid(dec_block.logits).data.cpu().numpy()\n",
    "    probs = probs.reshape(-1)\n",
    "    plt.figure(figsize=[18, 2])\n",
    "    plt.plot(probs)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd50c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stats['stats'])):\n",
    "    logit = stats['stats'][i]['logit']\n",
    "    prob = torch.sigmoid(logit)\n",
    "    print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddf0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7c444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
