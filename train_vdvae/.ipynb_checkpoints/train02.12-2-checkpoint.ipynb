{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba202ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 12 15:38:22 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:19:00.0 Off |                  Off |\r\n",
      "| 38%   65C    P2             131W / 450W |   3677MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:68:00.0 Off |                  Off |\r\n",
      "|  0%   56C    P8              28W / 450W |     28MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    0   N/A  N/A      3267      C   ...cpark/anaconda3/envs/ste/bin/python     3660MiB |\r\n",
      "|    1   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    1   N/A  N/A      1324      G   /usr/bin/gnome-shell                          8MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d51ab",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac98774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "\n",
    "# Data\n",
    "hp.dataset = 'ffhq_256'\n",
    "hp.data_root = '/home/scpark/data'\n",
    "hp.test_eval = True\n",
    "hp.image_channels = 3\n",
    "hp.n_batch = 32\n",
    "\n",
    "# Model\n",
    "hp.custom_width_str = \"\"\n",
    "hp.bottleneck_multiple = 0.25\n",
    "hp.no_bias_above = 64\n",
    "hp.num_mixtures = 10\n",
    "hp.width = 384\n",
    "hp.zdim = 16\n",
    "hp.dec_blocks = \"1x1,4m1,4x1,8m4,8x1,16m8,16x1,32m16,32x1\"\n",
    "hp.enc_blocks = \"32x1,32d2,16x1,16d2,8x1,8d2,4x1,4d4,1x1\"\n",
    "\n",
    "# Train\n",
    "hp.lr = 0.0002\n",
    "hp.wd = 0.01\n",
    "hp.adam_beta1 = 0.9\n",
    "hp.adam_beta2 = 0.9\n",
    "hp.warmup_iters = 100\n",
    "hp.ema_rate = 0.9999\n",
    "hp.grad_clip = 200.0\n",
    "hp.skip_threshold = 400.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777903",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b84157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.vdvae import Model\n",
    "from model.encoder.vdvae_encoder import Encoder\n",
    "from model.decoder.vdvae_decoder import Decoder\n",
    "from model.loss.dmol import Loss\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c033d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 7.7281494140625\n",
      "decoder 25.4820556640625\n",
      "loss 0.1468658447265625\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = Model(Encoder(hp), Decoder(hp), Loss(hp)).to(device)\n",
    "ema_model = None\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=hp.wd, lr=hp.lr, betas=(hp.adam_beta1, hp.adam_beta2))\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 1 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d4c2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3ac36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/lse/train_vdvae/train02.12-2/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model, optimizer = load(save_dir, 60000, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282214",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bca512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.vdvae_data import set_up_data\n",
    "\n",
    "hp, data_train, data_valid_or_test, preprocess_fn = set_up_data(hp)\n",
    "hp.image_size = 32\n",
    "train_loader = DataLoader(data_train, batch_size=hp.n_batch, drop_last=True, pin_memory=True)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98a82",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8269c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from util.train_helpers import update_ema\n",
    "\n",
    "def training_step(H, data_input, target, model, ema_model, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    data = {'x': data_input,\n",
    "            'x_target': target}\n",
    "    stats = model.forward(data)\n",
    "    stats['elbo'].backward()\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), H.grad_clip).item()\n",
    "    distortion_nans = torch.isnan(stats['distortion']).sum()\n",
    "    rate_nans = torch.isnan(stats['rate']).sum()\n",
    "    stats.update(dict(rate_nans=0 if rate_nans == 0 else 1, distortion_nans=0 if distortion_nans == 0 else 1))\n",
    "\n",
    "    skipped_updates = 1\n",
    "    # only update if no rank has a nan and if the grad norm is below a specific threshold\n",
    "    if stats['distortion_nans'] == 0 and stats['rate_nans'] == 0 and (H.skip_threshold == -1 or grad_norm < H.skip_threshold):\n",
    "        optimizer.step()\n",
    "        skipped_updates = 0\n",
    "        if ema_model is not None:\n",
    "            update_ema(model, ema_model, H.ema_rate)\n",
    "\n",
    "    stats.update(skipped_updates=skipped_updates, grad_norm=grad_norm)\n",
    "    return stats\n",
    "\n",
    "def show_samples(model, N):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        samples = model.sample(N)\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(len(samples)):\n",
    "        plt.subplot(1, N, i+1)\n",
    "        plt.imshow(samples[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "resize = transforms.Resize((hp.image_size, hp.image_size))\n",
    "\n",
    "while True:\n",
    "    for x in train_loader:\n",
    "        x[0] = resize(x[0].permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        data_input = data_input.to(device)\n",
    "        target = target.to(device)\n",
    "        stats = training_step(hp, data_input, target, model, ema_model, optimizer)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(step, 'elbo', stats['elbo'].item())\n",
    "            writer.add_scalar('elbo', stats['elbo'].item(), step)\n",
    "            writer.add_scalar('distortion', stats['distortion'].item(), step)\n",
    "            writer.add_scalar('rate', stats['rate'].item(), step)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            display.clear_output()\n",
    "            show_samples(model, 10)\n",
    "            \n",
    "        if step % 10000 == 0:\n",
    "            save(save_dir, step, model, optimizer)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(save_dir, step, model, optimizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "show_samples(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd50c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
