{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10538c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390f031b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 17 17:50:43 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   207W / 300W |  13582MiB / 80994MiB |     51%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    48W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    66W / 300W |   7089MiB / 80994MiB |     60%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    69W / 300W |   6865MiB / 80994MiB |     33%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    43W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    45W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A    319762      C   ...a3/envs/scpark/bin/python     6829MiB |\n",
      "|    1   N/A  N/A    335967      C   ...a3/envs/scpark/bin/python     6715MiB |\n",
      "|    2   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A    322106      C   ...a3/envs/scpark/bin/python     7051MiB |\n",
      "|    4   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A    335783      C   ...a3/envs/scpark/bin/python     6827MiB |\n",
      "|    5   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8964a",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c12f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_dec import Model\n",
    "from model.encoder.conv2d_encoder import Encoder\n",
    "from model.prior.normal_prior import Prior\n",
    "from model.latent.lse_latent import Latent\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5f2b",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a097b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21212121212121238\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 3\n",
    "hp.out_dim = 3\n",
    "hp.z_dim = 128\n",
    "hp.h_dims = [32, 64, 128, 256, 512]\n",
    "hp.M = 1024\n",
    "hp.N = 256\n",
    "hp.activation = F.sigmoid\n",
    "\n",
    "''' Find Optimum Log-Sigma'''\n",
    "from util.loglikelihood import get_optimum_log_sigma\n",
    "\n",
    "p_samples1 = torch.randn(hp.M, hp.z_dim).cuda()\n",
    "p_samples2 = torch.randn(hp.N, hp.z_dim).cuda()\n",
    "log_sigmas = np.array([get_optimum_log_sigma(p_samples1, p_samples2) for _ in range(100)])\n",
    "optimum_log_sigma = np.median(log_sigmas)\n",
    "print(optimum_log_sigma)\n",
    "\n",
    "hp.init_log_sigma = optimum_log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4bbd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 6.99169921875\n",
      "encoder.convs 5.9912109375\n",
      "encoder.linear 1.00048828125\n",
      "prior 0.0\n",
      "latent 3.814697265625e-06\n",
      "decoder 7.028697967529297\n",
      "decoder.linear 1.0078125\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(10):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933714f8",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f1e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 462368\r\n",
      "-rw-rw-r-- 1 scpark scpark    160196  1월 17 17:50 events.out.tfevents.1705480663.GPUSVR11\r\n",
      "-rw-rw-r-- 1 scpark scpark 473287823  1월 17 17:38 save_0\r\n",
      "-rw-rw-r-- 1 scpark scpark       882  1월 17 17:37 events.out.tfevents.1705480596.GPUSVR11\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train_celeba/train01.17-2/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, models, opt_g = load(save_dir, 0, models, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f1ada",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1292d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA\n",
    "\n",
    "class MyCelebA(CelebA):\n",
    "    \"\"\"\n",
    "    A work-around to address issues with pytorch's celebA dataset class.\n",
    "    \n",
    "    Download and Extract\n",
    "    URL : https://drive.google.com/file/d/1m8-EBPgi5MRubrm6iQjafK2QMHDBMSfJ/view?usp=sharing\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_integrity(self) -> bool:\n",
    "        return True\n",
    "\n",
    "root = '/data'\n",
    "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.CenterCrop(148),\n",
    "                                       transforms.Resize(hp.size),\n",
    "                                       transforms.ToTensor(),])\n",
    "train_dataset = MyCelebA(root, split='train', transform=train_transforms, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(148),\n",
    "                                      transforms.Resize(hp.size),\n",
    "                                      transforms.ToTensor(),])\n",
    "test_dataset = MyCelebA(root, split='test', transform=test_transforms, download=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd2a79",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19969caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985b324",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ddf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(_x[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64467eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49510\n",
      "lse_loss -0.0628692626953125\n",
      "recon_loss 0.006601388053968549\n",
      "49511\n",
      "lse_loss 0.10453033447265625\n",
      "recon_loss 0.0067000406794250015\n",
      "49512\n",
      "lse_loss -0.1560077667236328\n",
      "recon_loss 0.007151595642790198\n",
      "49513\n",
      "lse_loss 0.014032363891601562\n",
      "recon_loss 0.0071896601933985945\n",
      "49514\n",
      "lse_loss -0.024702072143554688\n",
      "recon_loss 0.006966164847835898\n",
      "49515\n",
      "lse_loss 0.0037128448486328123\n",
      "recon_loss 0.007578186597675085\n",
      "49516\n",
      "lse_loss 0.06573524475097656\n",
      "recon_loss 0.006923730485141277\n",
      "49517\n",
      "lse_loss -0.077679443359375\n",
      "recon_loss 0.007220345363020897\n",
      "49518\n",
      "lse_loss 0.0028316497802734373\n",
      "recon_loss 0.007253461051732302\n",
      "49519\n",
      "lse_loss -0.04845771789550781\n",
      "recon_loss 0.006950190290808678\n",
      "49520\n",
      "lse_loss 0.044315338134765625\n",
      "recon_loss 0.007591425906866789\n",
      "49521\n",
      "lse_loss 0.02335014343261719\n",
      "recon_loss 0.006749414326623082\n",
      "49522\n",
      "lse_loss -0.14405441284179688\n",
      "recon_loss 0.007317770691588521\n",
      "49523\n",
      "lse_loss 0.039385223388671876\n",
      "recon_loss 0.007230557873845101\n",
      "49524\n",
      "lse_loss -0.0021511077880859374\n",
      "recon_loss 0.006690934719517827\n",
      "49525\n",
      "lse_loss 0.21497802734375\n",
      "recon_loss 0.007237574830651283\n",
      "49526\n",
      "lse_loss -0.08992919921875\n",
      "recon_loss 0.006689070910215378\n",
      "49527\n",
      "lse_loss 0.0119842529296875\n",
      "recon_loss 0.007141414238139987\n",
      "49528\n",
      "lse_loss 0.09892005920410156\n",
      "recon_loss 0.007082846714183688\n",
      "49529\n",
      "lse_loss -0.019759750366210936\n",
      "recon_loss 0.007362455176189542\n",
      "49530\n",
      "lse_loss 0.029846572875976564\n",
      "recon_loss 0.007082873536273837\n",
      "49531\n",
      "lse_loss 0.08013343811035156\n",
      "recon_loss 0.007268271967768669\n",
      "49532\n",
      "lse_loss 0.01755180358886719\n",
      "recon_loss 0.007057570153847337\n",
      "49533\n",
      "lse_loss 0.01193695068359375\n",
      "recon_loss 0.006783481407910586\n",
      "49534\n",
      "lse_loss 0.03842239379882813\n",
      "recon_loss 0.007171405712142587\n",
      "49535\n",
      "lse_loss -0.02791290283203125\n",
      "recon_loss 0.006967114889994264\n",
      "49536\n",
      "lse_loss 0.11847381591796875\n",
      "recon_loss 0.007434005755931139\n",
      "49537\n",
      "lse_loss -0.10463943481445312\n",
      "recon_loss 0.006791470805183053\n",
      "49538\n",
      "lse_loss 0.0798095703125\n",
      "recon_loss 0.007360540982335806\n",
      "49539\n",
      "lse_loss -0.20944366455078126\n",
      "recon_loss 0.0069382611196488145\n",
      "49540\n",
      "lse_loss 0.08046302795410157\n",
      "recon_loss 0.0072964104823768135\n",
      "49541\n",
      "lse_loss 0.03680572509765625\n",
      "recon_loss 0.006962015619501471\n",
      "49542\n",
      "lse_loss -0.08209648132324218\n",
      "recon_loss 0.006825084891170263\n",
      "49543\n",
      "lse_loss 0.017730712890625\n",
      "recon_loss 0.006922873668372631\n",
      "49544\n",
      "lse_loss -0.08190574645996093\n",
      "recon_loss 0.006906470609828829\n",
      "49545\n",
      "lse_loss 0.06971397399902343\n",
      "recon_loss 0.007044297177344561\n",
      "49546\n",
      "lse_loss -0.06563835144042969\n",
      "recon_loss 0.0068486843723803755\n",
      "49547\n",
      "lse_loss 0.05391426086425781\n",
      "recon_loss 0.007053678948432207\n",
      "49548\n",
      "lse_loss 0.18141593933105468\n",
      "recon_loss 0.006629370572045446\n",
      "49549\n",
      "lse_loss 0.026377105712890626\n",
      "recon_loss 0.006739704078063369\n",
      "49550\n",
      "lse_loss -0.19113578796386718\n",
      "recon_loss 0.007094279117882252\n",
      "49551\n",
      "lse_loss 0.09644203186035157\n",
      "recon_loss 0.0072871900629252195\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, M=1024)\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'kl_loss' in key:\n",
    "                    loss = loss + data[key] * 0.00025\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            batch = next(iter(test_loader))\n",
    "            data = preprocess(batch)\n",
    "            \n",
    "            model = model_list[0]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, M=1024)\n",
    "            \n",
    "            plot(data['x'])\n",
    "            plot(data['y'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = model.prior.sample(10, hp.z_dim).to(device)\n",
    "                y = model.sample(z)\n",
    "                plot(y)\n",
    "                \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815ea878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b004a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
