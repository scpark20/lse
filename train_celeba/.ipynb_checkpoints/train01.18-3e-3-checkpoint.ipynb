{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10538c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390f031b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 18 16:57:58 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    68W / 300W |  16828MiB / 80994MiB |     17%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   55C    P0    81W / 300W |  13598MiB / 80994MiB |     64%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   140W / 300W |  15032MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    66W / 300W |   6899MiB / 80994MiB |     45%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    68W / 300W |   6895MiB / 80994MiB |     64%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    68W / 300W |    881MiB / 80994MiB |     35%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    78W / 300W |  15510MiB / 80994MiB |     24%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    71W / 300W |   7095MiB / 80994MiB |     44%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A    520251      C   ...a3/envs/scpark/bin/python     8395MiB |\n",
      "|    0   N/A  N/A    538757      C   ...a3/envs/scpark/bin/python     8395MiB |\n",
      "|    1   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A    337331      C   ...a3/envs/scpark/bin/python     6729MiB |\n",
      "|    1   N/A  N/A    346396      C   ...a3/envs/scpark/bin/python     6831MiB |\n",
      "|    2   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A    336772      C   ...a3/envs/scpark/bin/python     6599MiB |\n",
      "|    2   N/A  N/A    520565      C   ...a3/envs/scpark/bin/python     8395MiB |\n",
      "|    3   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A    336900      C   ...a3/envs/scpark/bin/python     6861MiB |\n",
      "|    4   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A    337132      C   ...a3/envs/scpark/bin/python     6857MiB |\n",
      "|    5   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    5   N/A  N/A    552429      C   ...a3/envs/scpark/bin/python      843MiB |\n",
      "|    6   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A    338773      C   ...a3/envs/scpark/bin/python     7073MiB |\n",
      "|    6   N/A  N/A    520611      C   ...a3/envs/scpark/bin/python     8399MiB |\n",
      "|    7   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    7   N/A  N/A    339012      C   ...a3/envs/scpark/bin/python     7057MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8964a",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c12f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_dec import Model\n",
    "from model.encoder.conv2d_encoder import Encoder\n",
    "from model.prior.uniform_prior import Prior\n",
    "from model.latent.blse_latent import Latent\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5f2b",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a097b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:39<00:00, 25.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.929292929292929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 3\n",
    "hp.out_dim = 3\n",
    "hp.z_dim = 128\n",
    "hp.h_dims = [32, 64, 128, 256, 512]\n",
    "hp.M = 1024\n",
    "hp.N = 256\n",
    "hp.const_sigma = False\n",
    "hp.z_activation = F.tanh\n",
    "hp.activation = F.sigmoid\n",
    "\n",
    "''' Find Optimum Log-Sigma'''\n",
    "from util.loglikelihood import get_optimum_log_sigma\n",
    "from tqdm import tqdm\n",
    "\n",
    "log_sigmas = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    p_samples1 = (torch.rand(hp.M, 1)*2-1).cuda()\n",
    "    p_samples2 = (torch.rand(hp.N, 1)*2-1).cuda()\n",
    "    log_sigmas.append(get_optimum_log_sigma(p_samples1, p_samples2, -10, 10, temperature=1.0))\n",
    "optimum_log_sigma = np.median(log_sigmas)\n",
    "print(optimum_log_sigma)\n",
    "\n",
    "hp.init_log_sigma = optimum_log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4bbd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 6.99169921875\n",
      "encoder.convs 5.9912109375\n",
      "encoder.linear 1.00048828125\n",
      "prior 0.0\n",
      "latent 3.814697265625e-06\n",
      "decoder 7.028697967529297\n",
      "decoder.linear 1.0078125\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(1):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933714f8",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f1e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train_celeba/train01.18-3e-3/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, model_list, optimizer_list = load_model_list(save_dir, 1505, model_list, optimizer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f1ada",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1292d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA\n",
    "\n",
    "class MyCelebA(CelebA):\n",
    "    \"\"\"\n",
    "    A work-around to address issues with pytorch's celebA dataset class.\n",
    "    \n",
    "    Download and Extract\n",
    "    URL : https://drive.google.com/file/d/1m8-EBPgi5MRubrm6iQjafK2QMHDBMSfJ/view?usp=sharing\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_integrity(self) -> bool:\n",
    "        return True\n",
    "\n",
    "root = '/data'\n",
    "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.CenterCrop(148),\n",
    "                                       transforms.Resize(hp.size),\n",
    "                                       transforms.ToTensor(),])\n",
    "train_dataset = MyCelebA(root, split='train', transform=train_transforms, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(148),\n",
    "                                      transforms.Resize(hp.size),\n",
    "                                      transforms.ToTensor(),])\n",
    "test_dataset = MyCelebA(root, split='test', transform=test_transforms, download=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd2a79",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19969caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985b324",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ddf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(_x[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64467eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134273\n",
      "lse_loss -0.6491866111755371\n",
      "recon_loss 0.009840774349868298\n",
      "134274\n",
      "lse_loss -0.649607241153717\n",
      "recon_loss 0.009698583744466305\n",
      "134275\n",
      "lse_loss -0.6520580053329468\n",
      "recon_loss 0.008798646740615368\n",
      "134276\n",
      "lse_loss -0.6506272554397583\n",
      "recon_loss 0.008411971852183342\n",
      "134277\n",
      "lse_loss -0.6452713012695312\n",
      "recon_loss 0.009377831593155861\n",
      "134278\n",
      "lse_loss -0.6489427089691162\n",
      "recon_loss 0.008570356294512749\n",
      "134279\n",
      "lse_loss -0.6504305005073547\n",
      "recon_loss 0.009081248193979263\n",
      "134280\n",
      "lse_loss -0.6497443914413452\n",
      "recon_loss 0.008837366476655006\n",
      "134281\n",
      "lse_loss -0.6489472389221191\n",
      "recon_loss 0.009459177032113075\n",
      "134282\n",
      "lse_loss -0.6472967863082886\n",
      "recon_loss 0.00793302059173584\n",
      "134283\n",
      "lse_loss -0.650519609451294\n",
      "recon_loss 0.008630524389445782\n",
      "134284\n",
      "lse_loss -0.651540994644165\n",
      "recon_loss 0.009024160914123058\n",
      "134285\n",
      "lse_loss -0.6473935842514038\n",
      "recon_loss 0.008602489717304707\n",
      "134286\n",
      "lse_loss -0.6478458642959595\n",
      "recon_loss 0.008876176550984383\n",
      "134287\n",
      "lse_loss -0.6475992202758789\n",
      "recon_loss 0.008976588025689125\n",
      "134288\n",
      "lse_loss -0.6489489078521729\n",
      "recon_loss 0.009853245690464973\n",
      "134289\n",
      "lse_loss -0.6485213041305542\n",
      "recon_loss 0.009231152012944221\n",
      "134290\n",
      "lse_loss -0.6473051309585571\n",
      "recon_loss 0.008874380961060524\n",
      "134291\n",
      "lse_loss -0.6496371626853943\n",
      "recon_loss 0.009443766437470913\n",
      "134292\n",
      "lse_loss -0.6449077129364014\n",
      "recon_loss 0.008407266810536385\n",
      "134293\n",
      "lse_loss -0.6488770246505737\n",
      "recon_loss 0.007817368023097515\n",
      "134294\n",
      "lse_loss -0.6524395942687988\n",
      "recon_loss 0.008525470271706581\n",
      "134295\n",
      "lse_loss -0.6509171724319458\n",
      "recon_loss 0.010371598415076733\n",
      "134296\n",
      "lse_loss -0.6483922004699707\n",
      "recon_loss 0.009076522663235664\n",
      "134297\n",
      "lse_loss -0.6447456479072571\n",
      "recon_loss 0.009488549083471298\n",
      "134298\n",
      "lse_loss -0.6424548625946045\n",
      "recon_loss 0.008475510403513908\n",
      "134299\n",
      "lse_loss -0.6469146013259888\n",
      "recon_loss 0.0076551418751478195\n",
      "134300\n",
      "lse_loss -0.6477426886558533\n",
      "recon_loss 0.009385136887431145\n",
      "134301\n",
      "lse_loss -0.6491731405258179\n",
      "recon_loss 0.01002533920109272\n",
      "134302\n",
      "lse_loss -0.6488026976585388\n",
      "recon_loss 0.008837856352329254\n",
      "134303\n",
      "lse_loss -0.6473798155784607\n",
      "recon_loss 0.010087491944432259\n",
      "134304\n",
      "lse_loss -0.6518654823303223\n",
      "recon_loss 0.00906186643987894\n",
      "134305\n",
      "lse_loss -0.6483955383300781\n",
      "recon_loss 0.009598156437277794\n",
      "134306\n",
      "lse_loss -0.6539309620857239\n",
      "recon_loss 0.010128635913133621\n",
      "134307\n",
      "lse_loss -0.646335244178772\n",
      "recon_loss 0.009423729032278061\n",
      "134308\n",
      "lse_loss -0.6472064256668091\n",
      "recon_loss 0.008350328542292118\n",
      "134309\n",
      "lse_loss -0.6464282870292664\n",
      "recon_loss 0.010037875734269619\n",
      "134310\n",
      "lse_loss -0.6515280604362488\n",
      "recon_loss 0.010089713148772717\n",
      "134311\n",
      "lse_loss -0.6485335826873779\n",
      "recon_loss 0.009040341712534428\n",
      "134312\n",
      "lse_loss -0.6526083946228027\n",
      "recon_loss 0.00958612747490406\n",
      "134313\n",
      "lse_loss -0.6488476395606995\n",
      "recon_loss 0.008097072131931782\n",
      "134314\n",
      "lse_loss -0.6539286375045776\n",
      "recon_loss 0.008533226326107979\n",
      "134315\n",
      "lse_loss -0.6502684354782104\n",
      "recon_loss 0.008272161707282066\n",
      "134316\n",
      "lse_loss -0.6487964987754822\n",
      "recon_loss 0.008582698181271553\n",
      "134317\n",
      "lse_loss -0.6508954167366028\n",
      "recon_loss 0.009057799354195595\n",
      "134318\n",
      "lse_loss -0.6487126350402832\n",
      "recon_loss 0.008358484134078026\n",
      "134319\n",
      "lse_loss -0.6525866985321045\n",
      "recon_loss 0.007690390106290579\n",
      "134320\n",
      "lse_loss -0.648755669593811\n",
      "recon_loss 0.009320217184722424\n",
      "134321\n",
      "lse_loss -0.6522457599639893\n",
      "recon_loss 0.00893960427492857\n",
      "134322\n",
      "lse_loss -0.6510802507400513\n",
      "recon_loss 0.008819205686450005\n",
      "134323\n",
      "lse_loss -0.6475872993469238\n",
      "recon_loss 0.008646292611956596\n",
      "134324\n",
      "lse_loss -0.6518830060958862\n",
      "recon_loss 0.009027860127389431\n",
      "134325\n",
      "lse_loss -0.6511685848236084\n",
      "recon_loss 0.008711183443665504\n",
      "134326\n",
      "lse_loss -0.6502114534378052\n",
      "recon_loss 0.009643210098147392\n",
      "134327\n",
      "lse_loss -0.6475595235824585\n",
      "recon_loss 0.008028671145439148\n",
      "134328\n",
      "lse_loss -0.6499006748199463\n",
      "recon_loss 0.009917052462697029\n",
      "134329\n",
      "lse_loss -0.6466587781906128\n",
      "recon_loss 0.008176742121577263\n",
      "134330\n",
      "lse_loss -0.6501621603965759\n",
      "recon_loss 0.007772918324917555\n",
      "134331\n",
      "lse_loss -0.6485728621482849\n",
      "recon_loss 0.009674282744526863\n",
      "134332\n",
      "lse_loss -0.6498355865478516\n",
      "recon_loss 0.010289166122674942\n",
      "134333\n",
      "lse_loss -0.6516814231872559\n",
      "recon_loss 0.008731361478567123\n",
      "134334\n",
      "lse_loss -0.6473665237426758\n",
      "recon_loss 0.008108172565698624\n",
      "134335\n",
      "lse_loss -0.6489594578742981\n",
      "recon_loss 0.010277314111590385\n",
      "134336\n",
      "lse_loss -0.6492770910263062\n",
      "recon_loss 0.009424588643014431\n",
      "134337\n",
      "lse_loss -0.6505239605903625\n",
      "recon_loss 0.009357232600450516\n",
      "134338\n",
      "lse_loss -0.6445391178131104\n",
      "recon_loss 0.00881532859057188\n",
      "134339\n",
      "lse_loss -0.6456446647644043\n",
      "recon_loss 0.008801347576081753\n",
      "134340\n",
      "lse_loss -0.6508010625839233\n",
      "recon_loss 0.008635226637125015\n",
      "134341\n",
      "lse_loss -0.6509337425231934\n",
      "recon_loss 0.008132020942866802\n",
      "134342\n",
      "lse_loss -0.6480420231819153\n",
      "recon_loss 0.009319020435214043\n",
      "134343\n",
      "lse_loss -0.6487647294998169\n",
      "recon_loss 0.009063297882676125\n",
      "134344\n",
      "lse_loss -0.6495420932769775\n",
      "recon_loss 0.009134858846664429\n",
      "134345\n",
      "lse_loss -0.6468135118484497\n",
      "recon_loss 0.008080127649009228\n",
      "134346\n",
      "lse_loss -0.6473091840744019\n",
      "recon_loss 0.008790101855993271\n",
      "134347\n",
      "lse_loss -0.6508404016494751\n",
      "recon_loss 0.007789652328938246\n",
      "134348\n",
      "lse_loss -0.650688886642456\n",
      "recon_loss 0.008892089128494263\n",
      "134349\n",
      "lse_loss -0.6500695943832397\n",
      "recon_loss 0.009483980014920235\n",
      "134350\n",
      "lse_loss -0.6498909592628479\n",
      "recon_loss 0.010035956278443336\n",
      "134351\n",
      "lse_loss -0.6493902206420898\n",
      "recon_loss 0.009352178312838078\n",
      "134352\n",
      "lse_loss -0.6455986499786377\n",
      "recon_loss 0.00827503390610218\n",
      "134353\n",
      "lse_loss -0.6487522125244141\n",
      "recon_loss 0.01015713345259428\n",
      "134354\n",
      "lse_loss -0.6460257768630981\n",
      "recon_loss 0.009545950219035149\n",
      "134355\n",
      "lse_loss -0.647918701171875\n",
      "recon_loss 0.008765367791056633\n",
      "134356\n",
      "lse_loss -0.6496509909629822\n",
      "recon_loss 0.009803684428334236\n",
      "134357\n",
      "lse_loss -0.6521627306938171\n",
      "recon_loss 0.008759419433772564\n",
      "134358\n",
      "lse_loss -0.649162769317627\n",
      "recon_loss 0.008618708699941635\n",
      "134359\n",
      "lse_loss -0.6459817886352539\n",
      "recon_loss 0.009094162844121456\n",
      "134360\n",
      "lse_loss -0.6470173597335815\n",
      "recon_loss 0.009399103932082653\n",
      "134361\n",
      "lse_loss -0.6491721272468567\n",
      "recon_loss 0.008446420542895794\n",
      "134362\n",
      "lse_loss -0.6484072804450989\n",
      "recon_loss 0.0075872233137488365\n",
      "134363\n",
      "lse_loss -0.6502593755722046\n",
      "recon_loss 0.008566474542021751\n",
      "134364\n",
      "lse_loss -0.6491068601608276\n",
      "recon_loss 0.0089483093470335\n",
      "134365\n",
      "lse_loss -0.6515530347824097\n",
      "recon_loss 0.008340287022292614\n",
      "134366\n",
      "lse_loss -0.6491696238517761\n",
      "recon_loss 0.009194561280310154\n",
      "134367\n",
      "lse_loss -0.649372398853302\n",
      "recon_loss 0.008847587741911411\n",
      "134368\n",
      "lse_loss -0.6488880515098572\n",
      "recon_loss 0.008649216033518314\n",
      "134369\n",
      "lse_loss -0.6478310823440552\n",
      "recon_loss 0.007743471767753363\n",
      "134370\n",
      "lse_loss -0.6466662883758545\n",
      "recon_loss 0.007899342104792595\n",
      "134371\n",
      "lse_loss -0.6510788202285767\n",
      "recon_loss 0.00863967277109623\n",
      "134372\n",
      "lse_loss -0.6476049423217773\n",
      "recon_loss 0.008559049107134342\n",
      "134373\n",
      "lse_loss -0.6453973054885864\n",
      "recon_loss 0.008547930978238583\n",
      "134374\n",
      "lse_loss -0.6493530869483948\n",
      "recon_loss 0.009459083899855614\n",
      "134375\n",
      "lse_loss -0.6493471264839172\n",
      "recon_loss 0.008329878561198711\n",
      "134376\n",
      "lse_loss -0.6467894315719604\n",
      "recon_loss 0.00884031131863594\n",
      "134377\n",
      "lse_loss -0.646619439125061\n",
      "recon_loss 0.008974305354058743\n",
      "134378\n",
      "lse_loss -0.6484870910644531\n",
      "recon_loss 0.010026724077761173\n",
      "134379\n",
      "lse_loss -0.650130033493042\n",
      "recon_loss 0.009099633432924747\n",
      "134380\n",
      "lse_loss -0.6454440355300903\n",
      "recon_loss 0.00828077457845211\n",
      "134381\n",
      "lse_loss -0.6499680280685425\n",
      "recon_loss 0.008875361643731594\n",
      "134382\n",
      "lse_loss -0.6477940082550049\n",
      "recon_loss 0.009689201600849628\n",
      "134383\n",
      "lse_loss -0.64632248878479\n",
      "recon_loss 0.009257974103093147\n",
      "134384\n",
      "lse_loss -0.6485214233398438\n",
      "recon_loss 0.009687526151537895\n",
      "134385\n",
      "lse_loss -0.6492743492126465\n",
      "recon_loss 0.007478445768356323\n",
      "134386\n",
      "lse_loss -0.6455425024032593\n",
      "recon_loss 0.00918133556842804\n",
      "134387\n",
      "lse_loss -0.645037055015564\n",
      "recon_loss 0.009002875536680222\n",
      "134388\n",
      "lse_loss -0.650780200958252\n",
      "recon_loss 0.009674401953816414\n",
      "134389\n",
      "lse_loss -0.6497068405151367\n",
      "recon_loss 0.008890479803085327\n",
      "134390\n",
      "lse_loss -0.6472787857055664\n",
      "recon_loss 0.007969431579113007\n",
      "134391\n",
      "lse_loss -0.6457269787788391\n",
      "recon_loss 0.008308328688144684\n",
      "134392\n",
      "lse_loss -0.6489080786705017\n",
      "recon_loss 0.009530013427138329\n",
      "134393\n",
      "lse_loss -0.6498239040374756\n",
      "recon_loss 0.008422614075243473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134394\n",
      "lse_loss -0.6509275436401367\n",
      "recon_loss 0.0076157632283866405\n",
      "134395\n",
      "lse_loss -0.6505864858627319\n",
      "recon_loss 0.009401185438036919\n",
      "134396\n",
      "lse_loss -0.6467557549476624\n",
      "recon_loss 0.008517108857631683\n",
      "134397\n",
      "lse_loss -0.6478832364082336\n",
      "recon_loss 0.009138114750385284\n",
      "134398\n",
      "lse_loss -0.6486729383468628\n",
      "recon_loss 0.008777483366429806\n",
      "134399\n",
      "lse_loss -0.6499589681625366\n",
      "recon_loss 0.00900910422205925\n",
      "134400\n",
      "lse_loss -0.6474297046661377\n",
      "recon_loss 0.008104059845209122\n",
      "134401\n",
      "lse_loss -0.6502306461334229\n",
      "recon_loss 0.00810583122074604\n",
      "134402\n",
      "lse_loss -0.6451563835144043\n",
      "recon_loss 0.008454418741166592\n",
      "134403\n",
      "lse_loss -0.6451001167297363\n",
      "recon_loss 0.00867003109306097\n",
      "134404\n",
      "lse_loss -0.648447573184967\n",
      "recon_loss 0.009318001568317413\n",
      "134405\n",
      "lse_loss -0.6479849815368652\n",
      "recon_loss 0.008174940012395382\n",
      "134406\n",
      "lse_loss -0.6515244245529175\n",
      "recon_loss 0.008261704817414284\n",
      "134407\n",
      "lse_loss -0.6513283252716064\n",
      "recon_loss 0.008266376331448555\n",
      "134408\n",
      "lse_loss -0.6507823467254639\n",
      "recon_loss 0.01019379310309887\n",
      "134409\n",
      "lse_loss -0.6496800780296326\n",
      "recon_loss 0.008833353407680988\n",
      "134410\n",
      "lse_loss -0.6511399745941162\n",
      "recon_loss 0.009080218151211739\n",
      "134411\n",
      "lse_loss -0.6506611704826355\n",
      "recon_loss 0.008859779685735703\n",
      "134412\n",
      "lse_loss -0.6510919332504272\n",
      "recon_loss 0.00926363654434681\n",
      "134413\n",
      "lse_loss -0.6498371958732605\n",
      "recon_loss 0.008331447839736938\n",
      "134414\n",
      "lse_loss -0.6483601331710815\n",
      "recon_loss 0.010416942648589611\n",
      "134415\n",
      "lse_loss -0.6493273377418518\n",
      "recon_loss 0.007614579051733017\n",
      "134416\n",
      "lse_loss -0.6481191515922546\n",
      "recon_loss 0.008180656470358372\n",
      "134417\n",
      "lse_loss -0.6492671966552734\n",
      "recon_loss 0.009174051694571972\n",
      "134418\n",
      "lse_loss -0.6437548398971558\n",
      "recon_loss 0.008648388087749481\n",
      "134419\n",
      "lse_loss -0.6484349966049194\n",
      "recon_loss 0.009328733198344707\n",
      "134420\n",
      "lse_loss -0.6436126232147217\n",
      "recon_loss 0.009518316015601158\n",
      "134421\n",
      "lse_loss -0.6440207958221436\n",
      "recon_loss 0.009047533385455608\n",
      "134422\n",
      "lse_loss -0.6495345234870911\n",
      "recon_loss 0.008445470593869686\n",
      "134423\n",
      "lse_loss -0.6469675302505493\n",
      "recon_loss 0.009193798527121544\n",
      "134424\n",
      "lse_loss -0.6478673219680786\n",
      "recon_loss 0.008240610361099243\n",
      "134425\n",
      "lse_loss -0.642935037612915\n",
      "recon_loss 0.008944476954638958\n",
      "134426\n",
      "lse_loss -0.6443966627120972\n",
      "recon_loss 0.009070102125406265\n",
      "134427\n",
      "lse_loss -0.6477800607681274\n",
      "recon_loss 0.007863400503993034\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, M=hp.M, temperature=1)\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'lse_loss' in key:\n",
    "                    loss = loss + data[key] * 3e-3\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            print(torch.exp(model_list[0].latent.log_sigma))\n",
    "            \n",
    "            batch = next(iter(test_loader))\n",
    "            data = preprocess(batch)\n",
    "            \n",
    "            model = model_list[0]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, M=hp.M)\n",
    "            \n",
    "            plot(data['x'])\n",
    "            plot(data['y'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = model.prior.sample(10, hp.z_dim).to(device)\n",
    "                y = model.sample(z)\n",
    "                plot(y)\n",
    "                \n",
    "            corrcoef = torch.corrcoef(data['z_copy'].T).abs().data.cpu().numpy()\n",
    "            # Plotting the matrix as a heatmap\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(corrcoef, cmap='viridis')\n",
    "            plt.colorbar()\n",
    "            plt.title('128x128 Matrix Heatmap')\n",
    "            plt.show()\n",
    "            \n",
    "            corrcoef = np.mean(corrcoef * (1-np.eye(len(corrcoef))))\n",
    "            writer.add_scalar('corrcoef', corrcoef, step)\n",
    "            \n",
    "            from util.mmd_penalty import mmd_penalty\n",
    "            opts = {'pz_scale': 1,\n",
    "                    'mmd_kernel': 'RBF', # 'IMQ', 'RBF'\n",
    "                    'pz': 'normal', # 'normal', 'sphere', 'uniform' \n",
    "                    'zdim': hp.z_dim\n",
    "                   } \n",
    "            e = (torch.rand_like(data['z_copy'])*2-1)\n",
    "            mmd = mmd_penalty(data['z_copy'], e, opts).item()\n",
    "            writer.add_scalar('MMD', mmd, step)\n",
    "    \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48201db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9200c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0666], device='cuda:0', grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display.clear_output()\n",
    "print(torch.exp(model_list[0].latent.log_sigma))\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "data = preprocess(batch)\n",
    "\n",
    "model = model_list[0]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data = model(data, M=hp.M)\n",
    "\n",
    "plot(data['x'])\n",
    "plot(data['y'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = model.prior.sample(10, hp.z_dim).to(device)\n",
    "    y = model.sample(z)\n",
    "    plot(y)\n",
    "\n",
    "corrcoef = torch.corrcoef(data['z_copy'].T).abs().data.cpu().numpy()\n",
    "# Plotting the matrix as a heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(corrcoef, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('128x128 Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f748f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677065f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d0d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
