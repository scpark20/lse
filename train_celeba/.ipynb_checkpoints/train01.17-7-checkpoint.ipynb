{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10538c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390f031b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 17 17:54:15 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    43W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   238W / 300W |  13594MiB / 80994MiB |     58%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   197W / 300W |   6633MiB / 80994MiB |      6%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   42C    P0   145W / 300W |   6897MiB / 80994MiB |     23%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    69W / 300W |   6895MiB / 80994MiB |     64%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    42W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    60W / 300W |   1025MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    45W / 300W |     35MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    1   N/A  N/A    319762      C   ...a3/envs/scpark/bin/python     6829MiB |\n",
      "|    1   N/A  N/A    337331      C   ...a3/envs/scpark/bin/python     6727MiB |\n",
      "|    2   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    2   N/A  N/A    336772      C   ...a3/envs/scpark/bin/python     6595MiB |\n",
      "|    3   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    3   N/A  N/A    336900      C   ...a3/envs/scpark/bin/python     6859MiB |\n",
      "|    4   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    4   N/A  N/A    337132      C   ...a3/envs/scpark/bin/python     6857MiB |\n",
      "|    5   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    6   N/A  N/A    338773      C   ...a3/envs/scpark/bin/python      987MiB |\n",
      "|    7   N/A  N/A      2426      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8964a",
   "metadata": {},
   "source": [
    "### Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c12f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main.enc_prior_latent_dec import Model\n",
    "from model.encoder.conv2d_encoder import Encoder\n",
    "from model.prior.uniform_prior import Prior\n",
    "from model.latent.swae_latent import Latent\n",
    "from model.decoder.conv2d_decoder import Decoder\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from util.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5f2b",
   "metadata": {},
   "source": [
    "### Model Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a097b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "hp = EasyDict()\n",
    "hp.size = 64\n",
    "hp.in_dim = 3\n",
    "hp.out_dim = 3\n",
    "hp.z_dim = 128\n",
    "hp.h_dims = [32, 64, 128, 256, 512]\n",
    "hp.activation = F.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4bbd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 6.99169921875\n",
      "encoder.convs 5.9912109375\n",
      "encoder.linear 1.00048828125\n",
      "prior 0.0\n",
      "latent 0.0\n",
      "decoder 7.028697967529297\n",
      "decoder.linear 1.0078125\n",
      "decoder.convs 5.9820556640625\n",
      "decoder.out_conv 0.038829803466796875\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_list = []\n",
    "optimizer_list = []\n",
    "for i in range(10):\n",
    "    model = Model(Encoder(**hp), Prior(**hp), Latent(**hp), Decoder(**hp))\n",
    "    model = model.to(device)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    optimizer_list.append(optimizer)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if len(name.split('.')) <= 2 and len(name) > 0:\n",
    "        print(name, get_size(module))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933714f8",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f1e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/scpark/save/lse/train_celeba/train01.17-7/'\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "!ls -lt $save_dir\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "\n",
    "if False:\n",
    "    step, models, opt_g = load(save_dir, 0, models, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f1ada",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1292d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA\n",
    "\n",
    "class MyCelebA(CelebA):\n",
    "    \"\"\"\n",
    "    A work-around to address issues with pytorch's celebA dataset class.\n",
    "    \n",
    "    Download and Extract\n",
    "    URL : https://drive.google.com/file/d/1m8-EBPgi5MRubrm6iQjafK2QMHDBMSfJ/view?usp=sharing\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_integrity(self) -> bool:\n",
    "        return True\n",
    "\n",
    "root = '/data'\n",
    "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.CenterCrop(148),\n",
    "                                       transforms.Resize(hp.size),\n",
    "                                       transforms.ToTensor(),])\n",
    "train_dataset = MyCelebA(root, split='train', transform=train_transforms, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(148),\n",
    "                                      transforms.Resize(hp.size),\n",
    "                                      transforms.ToTensor(),])\n",
    "test_dataset = MyCelebA(root, split='test', transform=test_transforms, download=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd2a79",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19969caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x, t = batch\n",
    "    data = {}\n",
    "    data['x'] = x.to(device)\n",
    "    data['t'] = t.to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985b324",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ddf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    _x = x.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    plt.figure(figsize=[18, 4])\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(_x[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64467eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5434\n",
      "swae_loss 0.013774618785828353\n",
      "recon_loss 0.010980203747749329\n",
      "5435\n",
      "swae_loss 0.013514271005988121\n",
      "recon_loss 0.010255744215101004\n",
      "5436\n",
      "swae_loss 0.013698309287428856\n",
      "recon_loss 0.0099625532515347\n",
      "5437\n",
      "swae_loss 0.01357286861166358\n",
      "recon_loss 0.011388182826340198\n",
      "5438\n",
      "swae_loss 0.013731272611767053\n",
      "recon_loss 0.010222153924405574\n",
      "5439\n",
      "swae_loss 0.01381289940327406\n",
      "recon_loss 0.010589314997196198\n",
      "5440\n",
      "swae_loss 0.014316816721111536\n",
      "recon_loss 0.01045344565063715\n",
      "5441\n",
      "swae_loss 0.012868034932762385\n",
      "recon_loss 0.010409307666122913\n",
      "5442\n",
      "swae_loss 0.013734767958521844\n",
      "recon_loss 0.010319717135280371\n",
      "5443\n",
      "swae_loss 0.012545007094740868\n",
      "recon_loss 0.010501121450215579\n",
      "5444\n",
      "swae_loss 0.013497788552194833\n",
      "recon_loss 0.011024309601634742\n",
      "5445\n",
      "swae_loss 0.013960905186831952\n",
      "recon_loss 0.010342354979366064\n",
      "5446\n",
      "swae_loss 0.012796018365770578\n",
      "recon_loss 0.010518696531653405\n",
      "5447\n",
      "swae_loss 0.012767326552420855\n",
      "recon_loss 0.010215844307094813\n",
      "5448\n",
      "swae_loss 0.01451960289850831\n",
      "recon_loss 0.01068595126271248\n",
      "5449\n",
      "swae_loss 0.013388377893716098\n",
      "recon_loss 0.010998890548944474\n",
      "5450\n",
      "swae_loss 0.013100908603519201\n",
      "recon_loss 0.01049337862059474\n",
      "5451\n",
      "swae_loss 0.01300749983638525\n",
      "recon_loss 0.011323958821594714\n",
      "5452\n",
      "swae_loss 0.013672243617475034\n",
      "recon_loss 0.010484129656106234\n",
      "5453\n",
      "swae_loss 0.01290224464610219\n",
      "recon_loss 0.010923763643950224\n",
      "5454\n",
      "swae_loss 0.013316346425563097\n",
      "recon_loss 0.011273532640188932\n",
      "5455\n",
      "swae_loss 0.012967339437454938\n",
      "recon_loss 0.010468072164803744\n",
      "5456\n",
      "swae_loss 0.013286347687244415\n",
      "recon_loss 0.010579171776771545\n",
      "5457\n",
      "swae_loss 0.013427781593054532\n",
      "recon_loss 0.010300280340015889\n",
      "5458\n",
      "swae_loss 0.013457286544144154\n",
      "recon_loss 0.010555480048060418\n",
      "5459\n",
      "swae_loss 0.01366553157567978\n",
      "recon_loss 0.010619791224598885\n",
      "5460\n",
      "swae_loss 0.012752241175621747\n",
      "recon_loss 0.010055145341902971\n",
      "5461\n",
      "swae_loss 0.01297045750543475\n",
      "recon_loss 0.010883568413555622\n",
      "5462\n",
      "swae_loss 0.013302739057689906\n",
      "recon_loss 0.01042865039780736\n",
      "5463\n",
      "swae_loss 0.013819420430809259\n",
      "recon_loss 0.010557738225907087\n",
      "5464\n",
      "swae_loss 0.013252981007099152\n",
      "recon_loss 0.010116794798523187\n",
      "5465\n",
      "swae_loss 0.01353540550917387\n",
      "recon_loss 0.010392762906849384\n",
      "5466\n",
      "swae_loss 0.014137360733002424\n",
      "recon_loss 0.010492936335504055\n",
      "5467\n",
      "swae_loss 0.01256918888539076\n",
      "recon_loss 0.01021915078163147\n",
      "5468\n",
      "swae_loss 0.013428631983697415\n",
      "recon_loss 0.010070056468248368\n",
      "5469\n",
      "swae_loss 0.012982650753110647\n",
      "recon_loss 0.010567803401499987\n",
      "5470\n",
      "swae_loss 0.012960877176374197\n",
      "recon_loss 0.010608093347400427\n",
      "5471\n",
      "swae_loss 0.013498897943645716\n",
      "recon_loss 0.010479861591011285\n",
      "5472\n",
      "swae_loss 0.013036851584911347\n",
      "recon_loss 0.010548622906208038\n",
      "5473\n",
      "swae_loss 0.012600903864949942\n",
      "recon_loss 0.010462856851518154\n",
      "5474\n",
      "swae_loss 0.014575689937919379\n",
      "recon_loss 0.010700520686805248\n",
      "5475\n",
      "swae_loss 0.01310250535607338\n",
      "recon_loss 0.010077587701380253\n",
      "5476\n",
      "swae_loss 0.013097859360277653\n",
      "recon_loss 0.01058196248486638\n",
      "5477\n",
      "swae_loss 0.014082064665853978\n",
      "recon_loss 0.01042422465980053\n",
      "5478\n",
      "swae_loss 0.013425376545637847\n",
      "recon_loss 0.009934341069310904\n",
      "5479\n",
      "swae_loss 0.014542192593216896\n",
      "recon_loss 0.010370038542896509\n",
      "5480\n",
      "swae_loss 0.013814801536500453\n",
      "recon_loss 0.01000337852165103\n",
      "5481\n",
      "swae_loss 0.012408068496733904\n",
      "recon_loss 0.010247059911489487\n",
      "5482\n",
      "swae_loss 0.013673713989555835\n",
      "recon_loss 0.010526112280786037\n",
      "5483\n",
      "swae_loss 0.014421641454100608\n",
      "recon_loss 0.010228827688843012\n",
      "5484\n",
      "swae_loss 0.013047816883772611\n",
      "recon_loss 0.010382422152906657\n",
      "5485\n",
      "swae_loss 0.013072724640369415\n",
      "recon_loss 0.010261813271790743\n",
      "5486\n",
      "swae_loss 0.01362280324101448\n",
      "recon_loss 0.010651637800037861\n",
      "5487\n",
      "swae_loss 0.013396998587995767\n",
      "recon_loss 0.010762055031955242\n",
      "5488\n",
      "swae_loss 0.013953772466629743\n",
      "recon_loss 0.010177421662956477\n",
      "5489\n",
      "swae_loss 0.01335592046380043\n",
      "recon_loss 0.011414559744298457\n",
      "5490\n",
      "swae_loss 0.01369937863200903\n",
      "recon_loss 0.010003540944308043\n",
      "5491\n",
      "swae_loss 0.014037586655467749\n",
      "recon_loss 0.009935764595866203\n",
      "5492\n",
      "swae_loss 0.012483640294522046\n",
      "recon_loss 0.010161740146577359\n",
      "5493\n",
      "swae_loss 0.013732087053358554\n",
      "recon_loss 0.010566281713545322\n",
      "5494\n",
      "swae_loss 0.014173598773777486\n",
      "recon_loss 0.010152872838079929\n",
      "5495\n",
      "swae_loss 0.013367869332432747\n",
      "recon_loss 0.010992449335753917\n",
      "5496\n",
      "swae_loss 0.01352249812334776\n",
      "recon_loss 0.010617671348154546\n",
      "5497\n",
      "swae_loss 0.014675498381257058\n",
      "recon_loss 0.011355032864958047\n",
      "5498\n",
      "swae_loss 0.014140976499766112\n",
      "recon_loss 0.011094695143401622\n",
      "5499\n",
      "swae_loss 0.012721423618495464\n",
      "recon_loss 0.010314594767987729\n",
      "5500\n",
      "swae_loss 0.012849748600274324\n",
      "recon_loss 0.010412312485277653\n",
      "5501\n",
      "swae_loss 0.014502882957458496\n",
      "recon_loss 0.010490632802248\n",
      "5502\n",
      "swae_loss 0.01305309683084488\n",
      "recon_loss 0.010512822959572076\n",
      "5503\n",
      "swae_loss 0.01335228541865945\n",
      "recon_loss 0.010595028754323721\n",
      "5504\n",
      "swae_loss 0.013963156100362539\n",
      "recon_loss 0.011662844568490982\n",
      "5505\n",
      "swae_loss 0.01317290822044015\n",
      "recon_loss 0.010243411455303431\n",
      "5506\n",
      "swae_loss 0.01383741358295083\n",
      "recon_loss 0.009423012752085924\n",
      "5507\n",
      "swae_loss 0.014036156237125397\n",
      "recon_loss 0.01139315515756607\n",
      "5508\n",
      "swae_loss 0.014585185889154672\n",
      "recon_loss 0.010371435340493918\n",
      "5509\n",
      "swae_loss 0.013661325257271529\n",
      "recon_loss 0.01068669967353344\n",
      "5510\n",
      "swae_loss 0.013242592103779316\n",
      "recon_loss 0.010511627234518529\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        print(step)\n",
    "        \n",
    "        loss_dict = {}\n",
    "        for model, optimizer in zip(model_list, optimizer_list):\n",
    "            data = preprocess(batch)\n",
    "\n",
    "            # Forward\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            data = model(data, M=len(data['x']))\n",
    "\n",
    "            # Backward\n",
    "            loss = 0\n",
    "            for key in data.keys():\n",
    "                if 'kl_loss' in key:\n",
    "                    loss = loss + data[key] * 0.00025\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                elif 'loss' in key:\n",
    "                    loss = loss + data[key]\n",
    "                    if key in loss_dict:\n",
    "                        loss_dict[key].append(data[key].item())\n",
    "                    else:\n",
    "                        loss_dict[key] = [data[key].item()]\n",
    "                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for key in loss_dict:\n",
    "            writer.add_scalar(key, np.mean(loss_dict[key]), step)\n",
    "            print(key, np.mean(loss_dict[key]))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            import matplotlib.pyplot as plt\n",
    "            display.clear_output()\n",
    "            \n",
    "            batch = next(iter(test_loader))\n",
    "            data = preprocess(batch)\n",
    "            \n",
    "            model = model_list[0]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = model(data, M=len(data['x']))\n",
    "            \n",
    "            plot(data['x'])\n",
    "            plot(data['y'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = model.prior.sample(10, hp.z_dim).to(device)\n",
    "                y = model.sample(z)\n",
    "                plot(y)\n",
    "                \n",
    "        if step % 10000 == 0:\n",
    "            save_model_list(save_dir, step, model_list, optimizer_list)\n",
    "                \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51af892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
